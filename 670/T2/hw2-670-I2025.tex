\documentclass[12pt]{memoir}

\def\nsemestre {I}
\def\nterm {Spring}
\def\nyear {2025}
\def\nprofesor {Clayton Shonkwiler}
\def\nsigla {MATH670}
\def\nsiglahead {Differential Geometry}
\def\nextra {HW2}
\def\nlang {ENG}
\input{../../headerVarillyDiff}
\DeclareMathOperator{\inv}{inv}
\begin{document}
%\begin{multicols}{2}

\begin{Ej}
    Let $A: V \to W$ be a linear map between vector spaces.
	\begin{enumerate}
		\item Show that the induced map $\exterior^k(V) \to \exterior^k(W)$ is well-defined by
		\[
			v_1 \wedge \ldots \wedge v_k \mapsto Av_1 \wedge \ldots \wedge Av_k
		\]
		(extending linearly to sums).
		
		\item Show that the map $A^*: W^* \to V^*$ defined by $(A^\ast(\eta))(v) := \eta(A(v))$ determines a map $\exterior^k(W^\ast) \to \exterior^k(V^\ast)$.
		
		\item Show that, if $V$ is an $n$-dimensional vector space, then the map $\exterior^n(V) \to \exterior^n(V)$ is multiplication by $\det A$.
	\end{enumerate}
\end{Ej}

\begin{ptcbr}
    To prove well-definedness of a map, it suffices to take two representatives of the same class and see that they map to the same place.
    \begin{enumerate}
        \item Consider then, without loss of generality,
        $$v_1\w v_2\wyw v_k=-(v_2\w v_1\wyw v_k).$$
        This second element we can reinterpret as 
        $$(-v_2)\w v_1\wyw v_k.$$
        Applying $\exterior^k(A)$ to this we get
        $$
        \left\lbrace
        \begin{aligned}
            &Av_1\w Av_2\wyw Av_k\\
            &A(-v_2)\w Av_1\wyw Av_k
        \end{aligned}
        \right.
        $$
        and using the fact that $A$ is linear we get 
        \begin{align*}
        A(-v_2)\w Av_1\wyw Av_k&=-(Av_2\w Av_1\wyw Av_k)\\
        &=Av_1\w Av_2\wyw Av_k
        \end{align*}
        and this is the desired representation of the image. Via linearity of $A$, we have that the induced map is multilinear. This allows to see that $\exterior^k(A)$ is well-defined.
        \item The map $A^\ast$ does indeed define a map from the exterior powers, namely $\exterior^k(A^\ast)$. \red{However I must admit I didn't do this one.}
        \item Observe that the dimension of $\exterior^n(V)$ is $1$ so that the induced linear map becomes
        $$\exterior^n(A)(v)=\la v,\quad v\in\exterior^n(V).$$
        Now the map $\exterior^n(A)$ is alternanting, multilinear and we may see that $I$ induces the identity map. By uniqueness of the determinant, this map must be the $\det(A)\.$.
    \end{enumerate}
\end{ptcbr}

\begin{Ej}
    Show that the vectors $v_1, \ldots , v_k \in V$ are linearly independent if and only if $v_1 \wedge \ldots \wedge v_k \neq 0$ as an element of $\exterior^k(V)$.
\end{Ej}

\begin{ptcbr}
    Assume that $\set{v_1,\dots,v_k}$ is linearly dependent, then if $\set{v_1,\dots,v_\l}$ is a maximally independent set, we may write any $v_i$ with $\l<i\leq k$ as a linear combination of $\set{v_1,\dots,v_l}$.\par
    This means that 
    \begin{align*}
        v_1\wyw v_k&=v_1\wyw v_{\l+1}\wyw v_k\\
        &=v_1\wyw \sum_{i=1}^kc_iv_i\wyw v_k\\
        &=\sum_{i=1}^kc_i(v_1\wyw v_i\wyw v_k)
    \end{align*}
    and all the summands will be zero as we will find repeated $v_i's$ in each term.\par
    \red{I couldn't quite piece it together with the other direction.}
\end{ptcbr}

\begin{Ej}
    We say that an element of $\exterior^k(V)$ is \emph{decomposable} if it can be written as $v_1 \wedge \ldots \wedge v_k$.
	\begin{enumerate}
		\item Suppose $v,w,x,y \in V$. Find necessary and sufficient conditions for $v \wedge w + x \wedge y \in \exterior^2(V)$ to be decomposable.
		
		\item Show that $\omega \in \exterior^{2}(\bR^4)$ is decomposable if and only if $\omega \wedge \omega = 0$.
	\end{enumerate}
\end{Ej}

\begin{ptcbr}
    \begin{enumerate}
        \item If it was the case that the element is decomposable, then there exist $a,b\in V$ such that
        $$v\w w+x\w y=a\w b.$$
        Observe now that 
        $$(a\w b)^{\w 2}=a\w b\w a\w b=0$$
        so that 
        $$(v\w w+x\w y)^{\w 2}=0.$$
        Expanding out this quantity we obtain
        \begin{align*}
            0=&(v\w w)^{\w 2}+(v\w u)\w(x\w y)+(x\w y)\w(v\w w)+(x\w y)^{\w 2}\\
            =&v\w u\w x\w y+(-1)^2(v\w w\w x\w y)\\
            =&2(v\w w\w x\w y)
        \end{align*}
        so it must occur that 
        $$v\w w\w x\w y=0$$
        or in other words, the vectors are linearly dependent. \red{I couldn't give myself time to finish this one.}
        \item Suppose $\om$ is a 2-wedge in $\bR^4$ and assume first that $\om$ was decomposable. Then there are $x,y\in\bR^4$ such that 
        $$\om^{\w 2}=(x\w y)^{\w 2}=(x\w y\w x\w y)=0.$$
        On the other hand, we may expand $\om$ in terms of the basis of $\exterior^2(\bR^4)$ 
        $$\om=\sum_{I\in\binom{\bonj{n}}{2}}c_{I}e_I.$$
        Observe that if $\om$ is \emph{not} decomposable, then there must exist $I,J$ partitioning $\bonj{4}$ and $c_I,c_J\neq 0$. When expanding $\om^{\w 2}$, this gives us a term in the sum 
        $$c_Ic_J e_{I\cup J}=c_Ic_J e_1\wyw e_4.$$
        which is non-zero. 
    \end{enumerate}
\end{ptcbr}

\begin{Ej}
    Let $V$ be an $n$-dimensional inner product space. We can extend the inner product from $V$ to all of $\exterior(V)$ by setting the inner product of homogeneous elements of different degrees equal to zero and by letting
	\[
		\langle w_1 \wedge \ldots \wedge w_k, v_1 \wedge \ldots \wedge v_k \rangle = \det \left(\langle w_i, v_j \rangle \right)_{i,j}
	\]
	and extending bilinearly. 
	
	Since $\exterior^n(V)$ is a one-dimensional real vector space, $\exterior^n(V) - \{0\}$ has two components. An \emph{orientation} on $V$ is a choice of component of $\exterior^n(V) - \{0\}$. If $V$ is an oriented inner product space, then there is a linear map $\star: \exterior(V) \to \exterior(V)$ called the star map, which is defined by requiring that for any orthonormal basis $e_1, \ldots , e_n$ for $V$,
	\begin{align*}
		\star(1) = \pm e_1 \wedge \ldots \wedge e_n,  & \qquad \star(e_1 \wedge \ldots \wedge e_n) = \pm 1, \\
		\star(e_1 \wedge \ldots \wedge e_k) & = \pm e_{k+1} \wedge \ldots \wedge e_n,
	\end{align*}
	where in each case we take ``$+$'' if $e_1 \wedge \ldots \wedge e_n$ is in the preferred component of $\exterior^n(V)$ and we take ``$-$'' otherwise. Notice that $\star: \exterior^k(V) \to \exterior^{n-k}(V)$.
	
	\begin{enumerate}
		\item Prove that if $e_1, \ldots , e_n$ is an orthonormal basis for $V$, then the $e_{i_1} \wedge \ldots \wedge e_{i_k}$ with $1 \leq i_1 < \ldots < i_k \leq n$ and $1 \leq k \leq n$ give an orthonormal basis for $\exterior(V)$.
		\item Prove that, as a map $\exterior^k(V) \to \exterior^k(V)$, $\star \star = (-1)^{k(n-k)}$.
		\item Prove that, for $\omega, \eta \in \exterior^k(V)$, their inner product is given by
		\[
			\langle \omega, \eta \rangle = \star (\omega \wedge \star \eta) = \star(\eta \wedge \star \omega).
		\]
	\end{enumerate}
\end{Ej}

\begin{ptcbr}
\begin{enumerate}
    \item Indeed, if $\set{e_i}_{i\in\bonj{n}}$ forms an orthonormal basis of $V$, then each collection 
    $$\set{e_{I}\:\ |I|=k,\ I\subseteq\bonj{n}},\quad e_{ I}=\exterior_{i\in I}e_i,$$
    spans the $k^{\text{th}}$ exterior power of $V$. In consequence the whole exterior algebra is spanned by the same collection letting $|I|$ range up to $n$.\par
    To see linear independence it suffices to see orthogonality. Between different index sizes it is clear via hypothesis. So let $I,J\in\binom{\bonj{n}}{k}$ and consider $\braket{e_I}{e_J}$. The obtained quantity is the determinant of the Gram matrix formed by the bases $\set{e_i}_{i\in I}$ and $\set{e_j}_{j\in J}$. The only possibility for the determinant in question to be non-zero is if $J$ is a permutation of $I$. But up to sign, this is the same basic element. Therefore, we get an orthonormal basis as desired.
    \item Proving this fact for a basic element suffices, so take $e_I$. $\star e_I$ is the element such that 
    $$e_I\w\star e_I=e_{I\cup I^c}=e_1\wyw e_n$$
    so that we must multiply by $(-1)^{\inv(\ttt{ToList}(I\cup I^c))}$. Such inversions can only happen between $I$ and $I^c$ because $I$ and $I^c$ themselves are already ordered. Thus 
    $$\star e_I=(-1)^{\inv(II^c)}e_{I^c}.$$
    Taking the star again we get 
    $$\star\star e_I=(-1)^{\inv(II^c)+\inv(I^cI)}e_I.$$
    \red{I couldn't finish the combinatorial argument which shows that the number of inversions in question is indeed $k(n-k)$.}
    \item Observe that if we prove this for basic elements, we are done by multilinearity. Consider the wedge:
    \begin{align*}
        \star(e_I\w \star e_J)&=\star(e_I\w e_{J^c})\\
        &=\star(e_{I\cup J^c})\\
        &=e_{I^c\cap J}
    \end{align*}
    On the other hand we obtain $e_{I\cap J^C}$. This calculation aligns with what it's supposed to be as the element $e_{I\cup J^c}$ lives in the top exterior power of $V$ as it has $k$ indices from $I$ and $n-k$ from $J^c$. Now we must interpret the set $I^c\cap J$ to see that the non-zero conditions of the inner product match up.\par
    Observe that if $I=J$ then $I^c\cap J$ and $I\cap J^c$ are the empty set. This leaves us with no wedges and so the result of the operation is $1$. In the other case, we get 0.
\end{enumerate}
\end{ptcbr}

\begin{Ej}
    Let $M^n$ be a closed manifold (i.e., a compact manifold without boundary) and let $\omega \in \Omega^1(M)$ so that $\omega_p \neq 0$ for all $p \in M$ (i.e., for all $p$, there exists $v \in T_pM$ so that $\omega_p(v) \neq 0$). Show that $\omega$ is not exact.
\end{Ej}
%https://math.stackexchange.com/questions/2998285/no-where-vanishing-exact-1-form-on-compact-manifold
%https://math.stackexchange.com/questions/2658091/the-global-minimum-is-necessarily-the-image-of-a-zero-of-the-derivative
\begin{ptcbr}
 It is equivalent to show that if $\om$ is exact, then there exists $p\in M$ so that $\om_p=0$.\par
So to our effect, assume $\om$ is exact. Then there is an $f\: M\to\bR$ such that $\dd f=\om$. As $M$ is compact, then there exists a point $p\in M$ at which $f$ attains a minimum (otherwise, we'll just have to switch signs). Our claim is that 
$$\dd f_p=0,$$
and to show this we take $v\in T_pM$ and a curve $\al\:\obonj{-\eps,\eps}\to M$ such that 
$$\al(0)=p,\quad\al'(0)=v.$$
We have that 
\begin{align*}
    \dd f_pv&=\dv{t}\eval_{t=0}f(\al(t))\\
    &=\lim_{h\to 0}\frac{f(\al(h))-f(\al(0))}{h}\\
    &=\lim_{h\to 0}\frac{f(\al(h))-f(p)}{h}
\end{align*}
And as $f(p)$ is a minimum of $f$ at $h=0$, it occurs that $f(\al(h))\geq f(p)$ for all $h$. For $h>0$ it happens that the quotient 
$$\frac{f(\al(h))-f(p)}{h}\word{is positive}$$
whereas for $h<0$ the quotient is negative, as the numerator is always positive. Then, as our limit exists, it should happen that it's zero. In conclusion $p$ is the point which makes $\om$ vanish.
\end{ptcbr}
\end{document} 