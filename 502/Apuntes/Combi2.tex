\documentclass[12pt]{memoir}

\def\nsemestre {I}
\def\nterm {Spring}
\def\nyear {2023}
\def\nprofesor {Maria Gillespie}
\def\nsigla {MATH502}
\def\nsiglahead {Combinatorics 2}
\def\nlang {ENG}
%\def\darktheme{}
\input{../../headerVarillyDiff}
\usepackage[enableskew]{youngtab}
\DeclareMathOperator{\ins}{ins}
\DeclareMathOperator{\rw}{rw}
\DeclareMathOperator{\rect}{rect}
\DeclareMathOperator{\sh}{sh}
\DeclareMathOperator{\std}{std}
\DeclareMathOperator{\Frob}{Frob}
\begin{document}
%\clearpage
\maketitle
%\thispagestyle{empty}
{\small 
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

This is the second semester of an introductory graduate-level course on combinatorics. We will be covering symmetric function theory, Young tableaux, counting with group actions, designs, matroids, finite geometries, and not-so-finite geometries.\par 
The goal of this class is to give an overview of the wide variety of topics and techniques in both classical and modern combinatorial theory.

\subsubsection*{Requirements}
Knowledge on theory of enumeration, generating functions, combinatorial species, the basics of graph theory, posets, partitions and tableaux, and basic symmetric function theory is required.
}
\newpage
\tableofcontents
%\begin{multicols}{2}
\chapter{Symmetric functions}

\section{Day 1|20230120}
\begin{Def}
$f(x_1,x_2,\dots)$ is \term{symmetric} if it's fixed under permutations of variables. For a permutation $\sg$ this is, 
$$f(x_{\sg(1),x_{\sg(2)}},\dots)=f(x_1,x_2,\dots).$$
\end{Def}

\begin{Ex}
    The function 
    $$f(x_1,\dots,x_4)=x_1^5+\dots+x_4^5$$ 
    is known as $p_5$ or $m_{(5)}$, where $p$ is the power-sum symmetric function and $m$, the monomial symmetric function.\par 
    We can have the function defined on infinitely many variables. Consider the function $g$ defined as 
    $$g=x_1^4x_2+x_1^4x_3+\dots+x_i^4x_j+\dots+3x_1+\dots+3x_i+\dots=m_{(4,1)}+3m_{(1)}.$$ 
\end{Ex}

Let us recall some \textbf{notation}, 
$$
\begin{cases}
    \La_R(x_1,\dots,x_n)\to\text{symmetric functions on }n\text{ variables over }R,\\
    \La_R(\un{x})\to\text{symmetric functions on \emph{infinitely} many variables over }R.
\end{cases}
$$
In our case $R=\bQ$, so the object of study is $\La_\bQ$.
\begin{Prop}\label{prop-dim-LambdaQ}
    The space $\La_\bQ^n$ is the space of symmetric functions of degree $n$. Its dimension is $p(n)$, the number of partitions of $n$.
\end{Prop}

This is because, for every such function we can decompose it into monomials and the monomial symmetric functions form a basis.

\subsection*{Bases of $\La_Q$}

Suppose $\la=(\la_1,\dots,\la_k)\vdash n$ with $\la_1\geq\dots\geq\la_k$. 

\subsubsection*{Monomial Symmetric Functions}

The function $m_\la(\un x)$ is the smallest symmetric function which contains the monomial $x_1^{\la_1}x_2^{\la_2}\dots x_k^{\la_k}$ as a term. In general 
$$m_\la=\sum_{i_1\neq\dots\neq i_k}x_{i_1}^{\la_1}\dots x_{i_k}^{\la_k}.$$

\begin{Ex}
    Consider the partition $(5,3)\vdash 8$. The function $m_{(5,3)}$ will be different depending on the number of variables:
    \begin{itemize}
        \itemsep=-0.4em
        \item In one variable we can't have monomials of the form $x_ix_j$, so $m_{(5,3)}=0$.
        \item In two variables we have $m_{(5,3)}(x,y)=x^5y^3+y^5x^3$.
        \item In three variables the function is 
        $$m_{(5,3)}(x,y,z)=x^5y^3+y^5z^3+z^5x^3+y^5x^3+z^5y^3+x^5z^3.$$
    \end{itemize}
    Considering some special cases, take the partition $(1,1,1,1)\vdash 4$, then 
\begin{align*}
    m_{(1,1,1,1)}(u,v,x,y,z)&=uvxy+vxyz+xyzu+yzuv+zuvx\\
    &=uvxy+uxyz+uvyz+uvxz+vxyz.
\end{align*}
For cases with less than $4$ variables the function is zero and in exactly four, it has $1$ term. The partition $(4)\vdash 4$ returns the function 
$$m_{(4)}(x)=x^4,\ m_{(4)}(x,y)=x^4+y^4,\ m_{(4)}(x,y,z)=x^4+y^4+z^4,$$
and so on with any number of variables.
\end{Ex}

\begin{Rmk}
    The number of terms in $m_\la(x_1,\dots,x_d)$ is \red{I actually don't know}, while the degree of $m_\la$ is $|\la|=n$.
\end{Rmk}

\subsubsection{Elementary Symmetric Functions}

\begin{Def}
For any $r\in\bN$, the elementary symmetric function $e_r$ is $m_{(1,1,\dots,1)}$ ($r$ ones). For $\la$, a partition, $e_\la=\prod e_{\la_i}$. As an alternative for $m_{(1,1,\dots,1)}$ we can also write 
$$e_r(x_1,\dots,x_d)=\sum_{1\leq i_1<\dots<i_r\leq n}x_{i_1}\dots x_{i_r}.$$ 
\end{Def}

\begin{Ex}
    Let us calculate $e_{(2,1)}$ for $1$ through $3$ variables. When we have $e_{(2,1)}(x)=e_2(x)e_1(x)$, we can't compute $e_2(x)$ because there are no two-term monomials with only one variable. On two variables we have the following
    \begin{align*}
        e_{(2,1)}(x,y)&=e_2(x,y)e_1(x,y)=(xy)(x+y)=x^2y+y^2x
    \end{align*}
    and when talking about $3$ variables the following happens:
    \begin{align*}
        e_{(2,1)}(x,y,z)&=e_2(x,y,z)e_1(x,y,z)\\
        &=(xy+yz+zx)(x+y+z)\\
        &=x^2y+y^2z+z^2x+y^2x+z^2y+x^2z+2xyz.
    \end{align*}
    Consider now the partitions $(2,2,2,2)$ and $(5)$. Then 
    $$e_{(2,2,2,2)}=e_2^4\To e_{(r,r,\dots,r)}=e_r^{m_r(\la)}$$
    where $m_i(\la)$ is number of parts of $\la$ equal to $i$. For the partition $(5)$ we have that $e_{(5)}=e_5$ and in general $e_{(n)}=e_n$.
\end{Ex}

\begin{Rmk}
    As before \red{we don't know how many terms per function}, but knowing $m$ implies knowing $e$. As for the degree, it holds that $\deg(e_\la)=|\la|$.
\end{Rmk}

\subsubsection{Homogenous Symmetric Functions}
%https://garsia.math.yorku.ca/ghana03/chapters/mainfile3.pdf
%https://www.symmetricfunctions.com/index.htm
%http://www.mathematicalgemstones.com/gemstones/diamond/summary-symmetric-functions-transition-table/

\begin{itemize}
    
    \item Homogenous: $h_\la=\prod h_{\la_i}$ and $h_d=x_1^d+\dots+x_1^{d-1}x_2+\dots+x_1^{d-2}x_2^2+x_1^{d-2}x_2x_3+\dots$. In general $h_d=\sum_{\la\vdash d}m_\la$.
    \item Power sum: $p_\la=\prod p_{\la_i}$ and $p_d=\sum x_i^d$.
\end{itemize}

For Schur basis recall SSYT 

\begin{Ex}
    Consider $\la=(5,4,1)$, rows $\leq\to$ and columns $<$, we associate the monomial $x_1^2x_2^3x_3^3x_4^2:=x^T$.
\end{Ex}

\begin{itemize}
    \itemsep=-0.4em
    \item Schur: $s_\la=\sum_{T\in SSYT(\la)}x^T$ but also $\sum K_{\la\mu}m_\mu$ where the sum is over SSYT of shape $\la$, content $\mu$.
\end{itemize}

\subsubsection{Schur function motivation (preview)}

The first place they showed up is in the representation theory of Lie group.  The function $s_\la(x_1,\dots,x_n)$ is a character of irreducible polynomial representations of $GL_n$. In theoretical physics we have matrix groups acting on particles, representations are smaller matrix groups of things that they are mapping to. We want to take tensor product and direct sums of representations, the tensor product is related to multiplication of Schur function while direct sum into sum of Schur functions.\par 
There's also the Schur-Weyl duality which takes representations into the Weyl group. Under the \emph{Frobenius map}, $s_\la$ corresponds to irreducible representations of $S_n$.\par 
A more modern application of Schur function goes into geometry, $s_\la$ correspond to Schubert varieties in Grassmannians. Multiplication corresponds to interesections and sum to unions.\par 
There's also context in Probability Theory. But in the end, Schur positivity is important because of this connections. 

\begin{Def}
    $f\in\La$ is \term{Schur-positive} if $f=\sum c_\la s_\la$, $c_\la\geq 0$.
\end{Def}

\begin{Ex}
    $3s_{(2,1)}+2s_{(3)}$ schur pos but change $2$ to $-\half$ then not.
\end{Ex}

\section{day 2}

\subsection*{Alg defn Schur fncs}

\begin{Def}
    A function is \term{antisymmetric} if for $\pi\in S_n$,
    $$f(x_{\pi(1)},\dots,x_{\pi(n)})=\sgn(\pi)f(x_1,\dots,x_n).$$
\end{Def}

\begin{Ex}
    The following functions are antisymmetric:
    \begin{enumerate}
        \itemsep=-0.4em
        \item $f(x,y)=x-y$ then $f(y,x)=-f(x,y)$.
        \item $g(x,y)=(x-y)(x+y)$.
        \item $h(x,y)=x^2y-y^2x$.
    \end{enumerate}
\end{Ex}

Notice that the last function can factor as $h=-xy(x-y)$. We claim that this is always the case.

\begin{Lem} 
    Every antisymmetric polynomial $f$ in two variables $x,y$ can factor as $f(x,y)=(x-y)g(x,y)$ where $g$ is symmetric.
\end{Lem}

\begin{ptcbp}
Suppose $f$ is antisymmetric, then $f(x,x)=0$ by taking $y=x$. This means that $(x-y)\mid f$. Thus $f(x,y)=(x-y)g(x,y)$ and we now need to show that $g$ is symmetric. 
$$g(y,x)=\frac{f(y,x)}{y-x}=\frac{-f(x,y)}{-(x-y)}=\frac{f(x,y)}{x-y}=g(x,y).$$
\end{ptcbp}

\subsubsection*{Monomial Antisymmetric Functions}

\begin{Def}
Given a strict partition $\la=(\la_1,\dots,\la_k)$, $\la_1>\dots>\la_k$, we define 
$$a_\la(x_1,\dots,x_n)=x_1^{\la_1}\cdots x_k^{\la_k}\pm\text{similar terms}=\sum_{\pi\in S_n}\sgn(\pi)\prod_{k}x_{\pi(k)}^{\la_k}.$$ 
This $a_\la$ can be zero. 
\end{Def}

\begin{Ex}
    For two variables we've seen some antisymmetric polynomials. Let us calculate 
    $$a_{(3,1)}(x,y)=x^3y-y^3x.$$
    The smallest possible example in 3 variables is 
    $$a_{(2,1,0)}(x,y,z)=x^2y+y^2z+z^2x-y^2x-z^2y-x^2z.$$
    This can be factored as $(x-y)(y-z)(x-z)$. A similar construction gives us
    $$a_{(4,2,0)}(x,y,z)=x^4y^2+y^4z^2+z^4x^2-y^4x^2-z^4y^2-x^4z^2,$$
    but how does this factor? We get 
    $$a_{(4,2,0)}(x,y,z)=(x^2-y^2)(y^2-z^2)(x^2-z^2)=a_{(2,1,0)}(x,y,z)(x+y)(y+z)(x+z).$$
\end{Ex}

\begin{Lem}
The set $\set{a_\la}_{\la\ \text{strict}}$ is a basis of the antisymmetric polynomials over $\bQ$, $A_\bQ$. Even more any $a_\la$ is divisible by $a_\rho$ where $\rho=(n-1,n-2,\dots,2,1,0)$. 
\end{Lem}

As an algebra generator, $a_\rho$ is a generator.
\begin{ptcbp}
    \red{WRITE}
\end{ptcbp}

\begin{Prop}
The $a_\rho$ antisymmetric function is also the \term{Vandermonde determinant}: 
$$a_\rho=\det\begin{pmatrix}
    x_1^{n-1}&x_1^{n-2}&\dots&x_1^2&x_1&1\\
    x_2^{n-1}&x_2^{n-2}&\dots&x_2^2&x_2&1\\
    \vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\
    x_n^{n-1}&x_n^{n-2}&\dots&x_n^2&x_n&1\\
\end{pmatrix}$$
\end{Prop}

\subsubsection{Schur Polynomials}

\begin{Def}
    The \term{Schur polynomial} of $\la\in\text{Par}$ is 
    $$s_\la(x_1,\dots,x_n)=\frac{a_{\la+\rho}(\un{x})}{a_\rho(\un x)}.$$
    Here $\la+\rho$ is the pointwise sum as arrays.
\end{Def}

\begin{Rmk}
This is the Weyl character proof. 
\end{Rmk}

The following proof is due to Proctor(1987) \red{find ref}

\begin{Lem}
    Any $a_\la$ can be seen as a determinant in the following way:
    $$a_\la(\un x)=\det\begin{pmatrix}
        x_1^{\la_1}&x_1^{\la_2}&\dots&x_1^{\la_n}\\
        x_2^{\la_1}&x_2^{\la_2}&\dots&x_2^{\la_n}\\
        \vdots&\vdots&\ddots&\vdots\\
        x_n^{\la_1}&x_n^{\la_2}&\dots&x_n
    \end{pmatrix}$$
\end{Lem}
\begin{ptcbp}
    We want to see that 
    $$\frac{a_{\la+\rho}(\un{x})}{a_\rho(\un x)}=\sum x^T$$
    where the sum ranges through $T$'s which are SSYT(la) with max entry $n$. 
    \begin{enumerate}
        \item We will show a recursion for the combinatorial definition that the character formula will also satisfy. It holds that 
        $$s_\la(\un x)=\sum s_\mu(\un x)x_n^{|\la|-|\mu|}$$
        where $\mu$ has $n-1$ parts with $\la_1\geq\mu_1\geq\la_2\geq\mu_2\dots$. 
        \item We also show that the ratio of determinants satisfies the same recursion. 
    \end{enumerate}
\end{ptcbp}

\begin{Ex}
    Consider $\la=(8,8,4,1,1)$ and $\mu=(8,5,2,1)$, then $\la\less\mu$ is a skew-table in which we can fill in $n$'s
\end{Ex}

\begin{Cor}
The Schur polynomials are a basis of $\La_\bQ$. 
\end{Cor}

\section{Day 3|20230125}

Recall $\La=\bQ[e_1,e_2,\dots]$ where the $e_j$'s are the elementary symmetric functions. So the $e_j$'s are algebraic generators of $\La$ and they're algebraically independent. Equivalently, as a vector space, $\set{e_\la\:\ \la\in\text{Par}}$ is a basis.

\begin{Prop}
    A homomorphism $f\:\La\to\La$ ($f(a+b)=f(a)+f(b),\ f(ab)f(a)f(b)$ for $a,b\in\La$) is fully determined by where it sends the $e_i's$. 
\end{Prop}

\begin{Def}
    The map $\om\in\End(\La)$ will send $e_j$ to $h_j$. 
\end{Def}

\begin{Ex}
    Consider $f=3e_{(2,1)}+2e_3$, then applying $\om$ we get 
    $$\om(f)=\om(3e_{(2,1)}+2e_3)=3h_{(2,1)}+2h_3.$$
    For $p_2$, we can decompose to $e_1^2-2e_2$. So 
    $$\om(p_2)=\om(e_1^2-2e_2)=h_1^2-2h_2$$
    and we can expand this last expression into 
    $$(x_1+x_2+\dots)^2-2(x_1^2+x_2^2+\dots+x_1x_2+x_1x_3+\dots)=-x_1^2-x_2^2-\dots$$
    and we recognize this last term as $-p_2$. \emph{This is not a coincidence.}
\end{Ex}

\begin{Th}
The map $\om$ is involutive.
\end{Th}

\begin{ptcbp}
    It suffices to prove that $\om(h_j)=e_j$. We will use power expansions and generating functions. We have 
    $$H(t)=\frac{1}{1-x_1t}\frac{1}{1-x_2t}\dots=\sum h_n(\un x)t^n,$$
    and this comes from expanding the $1/(1-y)$'s as geometric series. When collecting the coefficients of $t^n$ we get exactly $h_n(\un x)$. Similarly, for the elementary symmetric functions, 
    $$E(t)=(1+x_1t)(1+x_2t)\dots=\sum e_nt^n.$$
    When multiplying to obtain the coefficient of $t^n$ we get a plethora of different $x_j$'s which form the $e_j$'s. Now from this expressions we have $H(t)E(-t)=1$ which means that
    $$\left(\sum h_n(\un x)t^n\right)\left(\sum e_n(\un x)(-t)^n\right)\To \sum_{k=0}^{n}(-1)^ke_kh_{n-k}=0,\ n\geq 1.$$
    Now applying the map to the equation we get 
    $$\om\left(\sum_{k=0}^{n}(-1)^ke_kh_{n-k}\right)=\sum_{k=0}^{n}(-1)^kh_k\om(h_{n-k})=0.$$
    After reindexing, we get that both $e_j$'s and $\om(h_j)$'s are determined recursively by the $h_j$'s in the same way. Thus we conclude that $\om(h_j)=e_j$. 
\end{ptcbp}

\begin{Lem}
    The following equation holds for the power-sum symmetric functions:
    $$\exp\left(\sum\frac{1}{n}p_n(\un x)p_n(\un y)\right)=\prod_{i,j=1}^\infty\frac{1}{1-x_iy_j}=\:\Om(\un x,\un y).$$
    It also holds that 
    $$\Om(\un x,\un y)=\sum_la\frac{1}{z^\la}p_\la(\un x)p_\la(\un y)$$
    where $z_\la=\prod k^{m_k}m_k!$ where $m_k$ is the number of parts of $\la$ equal to $k$. 
\end{Lem}

\begin{ptcbp}
    We will prove both parts separately. For the first equation we will take the logarithm on both sides: 
    $$\sum\frac{1}{n}p_n(\un x)p_n(\un y)=\log\left(\prod_{i,j=1}^\infty\frac{1}{1-x_iy_j}\right)$$
    and after manipulating the logarithm we get 
    $$\sum_{i,j=1}^\infty(\log(1)-\log(1-x_iy_j))=\sum_{i,j=1}^\infty\sum_{n=1}^\infty \frac{1}{n}x_i^ny_j^n.$$
    We can separate\footnote{Are we using Fubini-Tonelli here?} into 
    $$\sum_{n=1}^\infty\frac{1}{n}\left(\sum_i x_i^n\right)\left(\sum_j y_j^n\right).$$
    Now taking $\exp$ on both sides we get equality.\par 
    By not removing the exponential we get the following expression
    $$\exp\left(\sum\frac{1}{n}p_n(\un x)p_n(\un y)\right)=\sum_{k=0}^\infty\frac{1}{k!}\left(\sum\frac{1}{n}p_n(\un x)p_n(\un y)\right)^k.$$
    To get a term of the form $p_\la(\un x)p_\la(\un y)$ we have to choose which parts of the $\la$ come from each of the factors in $\sum\frac{1}{n}p_n(\un x)p_n(\un y)$. If $\l(\la)=k$ then it comes from the $k^\textsuperscript{th}$ term in the exponential sum. If $\la=(\la_1,dots,\la_1,\dots,2,\dots,2,1,\dots,1)$ with $m_{\la_1}$ $\la_1$'s, $m_1$ $1$'s, then out of $k$ elements we have to choose $m_1$ $1$'s and so on. Thus there are $\binom{k}{m_{\la_1},\dots,m_1}$ choices and each $i$ in $\la$ comes with a $\frac{1}{i}$. Therefore the coefficient of $p_\la(\un x)p_\la(\un y)$ is 
    $$\frac{1}{k!}\frac{k!}{m_1!m_2!\dots}\frac{1}{1^{m_1}}\frac{1}{2^{m_2}}\dots=\frac{1}{z_\la}.$$
\end{ptcbp}

\begin{Lem}
    We have the following identities 
    $$\exp\left(\sum\frac{(-1)^{n-1}}{n}p_n(\un x)p_n(\un y)\right)=\prod_{i,j=1}^\infty\frac{1}{1+x_iy_j}=\sum_\la\frac{(-1)^{n-\l(\la)}}{z_\la}p_\la(\un x)p_\la(\un y).$$
\end{Lem}

\begin{Lem}\label{lem:james1}
    Another equality for $\Om(\un x,\un y)$ is 
    $$\Om(\un x,\un y)=\sum_\la m_\la(\un x)h_\la(\un y)$$
\end{Lem}

\begin{Th}
    It holds that $\om(p_\la)=(-1)^{n-k}p_\la$ where $k$ is the number of parts of $\la$.
\end{Th}

\begin{ptcbp}
    Applying $\om$ to $\Om$, but \emph{only working with $\un y$ variables} we get 
    $$\om(\Om)=\om\left(\sum_\la m_\la(\un x)h_\la(\un y)\right)=\sum_\la m_\la(\un x)e_\la(\un y)=\prod_{i,j=1}^\infty (1+x_iy_j)=\sum_{\la}\frac{1}{z_\la}(-1)^{n-k_\la}p_\la(\un x)p_\la(\un y).$$
    Comparing coefficients with 
    $$\om\left(\sum_la\frac{1}{z^\la}p_\la(\un x)p_\la(\un y)\right)$$
    we get the result.
\end{ptcbp}

\section{Day 4|20230127}

To continue exploring the ring of symmetric functions we need a couple of tools. One of them is the involution which we have already seen. But the other one is a scalar product which is compatible with the multiplication.

\subsection{Hall Inner Product}

Recall an inner product is a function 
$$\braket*{-}{-}\:\ V\x V\to \bQ$$
which is bilinear $\braket{u+v}{w}=\braket{u}{w}+\braket{v}{w}$ and the same on the other entry. For scalars the following behavior is expected $\braket{\la u}{v}=\braket{u}{\la v}=\la\braket{u}{v}$. Recall that if the base field is the complex numbers, then the inner product is Hermitian.

\begin{Def}
    We say that two vectors are \term{orthogonal} when $\braket{u}{v}=0$.
\end{Def}

This gives us a possible decomposition of space into several components. Suppose that $\set{u_\la}_{\la\in\text{Par}(n)},\set{v_\la}_{\la\in\text{Par}(n)}$ are basis of $\La^n$. So we would like a condition such as 
$$\braket{u_\la}{v_\mu}=\begin{cases}
    0\ \la\neq\mu,\\
    1\ \la=\mu.
\end{cases}$$

If we cap the dimension this says that $\braket{u}{v}$ is the usual dot product. But in infinite dimensions we don't have matrices. We'll call this basis \term{dual} to one another. If miraculously we have the same basis, then this basis is \term{orthonormal}.

\begin{Def}[Phillip Hall]
    The \term{Hall inner product} is defined so that $\braket{m_\la}{h_\mu}=\dl_{\la\mu}$.
\end{Def}

By defining the product on two basis, we have defined it for all other elements by bilinearity. 

\begin{Lem}
    The Hall inner product is symmetric.
\end{Lem}

\begin{Th}
    The Hall inner product is positive definite, this is $\braket{f}{f}\geq 0$ and equality is achieved when $f=0$.
\end{Th}

It's important to note that this statement is symmetric. However we are talking about an asymmetric definition. Last, before proving the statement we need a criteria for dual bases. But importantly, recall the result from last lecture: \ref{lem:james1}

\begin{Th}
    If ${u_\la},\set{v_\mu}$ are dual, then $\sum_\la u_\la v_\la=\Om$. 
\end{Th}

\begin{ptcbp}
    Fix a partition of $n$, then 
    $$\dl_{\la\mu}=\braket{m_\la}{h_\mu}=\braket{\sum_{\rho\vdash n}\al_{\la_\rho}u_\rho}{\sum_{\tau\vdash n}\bt_{\mu_\tau}v_\tau}=\sum_{\rho,\tau}\al_{\la_\rho}\bt_{\mu_\tau}\braket{u_\rho}{v_\tau}.$$
    We want $\braket{u_\rho}{v_\tau}=\dl_{\rho\tau}$, to that effect name $A_{\rho\tau}$ the matrix whose entries are $\braket{u_\rho}{v_\tau}$.\par 
    As $u$ and $v$ are dual bases, we have that $A=\id$. Thus $I=\al\bt^\sT$ and now $\dl_{\rho\tau}=\sum \al_{\la_\rho}\bt_{\la_\tau}$. We are now going to use the hypothesis and the interpretation of $m,h$ in the $u,v$ basis. We have 
    $$\Om=\sum\left(\sum\al u\right)\left(\sum\bt v\right)=\sum\left(\sum \al\bt\right)uv=\sum uv$$
    so the inner sum must be one and thus we are done. 
\end{ptcbp}

\begin{Cor}
    For the Hall inner product it holds that $\braket{p_\la}{p_\mu}=z_\la\dl_{\la\mu}$.
\end{Cor}

The key is to recall that $p_\la$ is an eigenfunction of $\om$. Also 1.3.5. By using a power-sum decomposition it is possible to prove that the Hall inner product is positive definite.

\begin{Cor}
    The $\om$ involution is orthogonal with respect to $\braket{-}{-}$. This is $\braket{\om f}{\om g}=\braket{f}{g}$. 
\end{Cor}
 
Once again, the idea is to transfer to power-sum and use the fact that it's an eigenfunction.

\section{Interim 1}

\begin{Th}[Fundamental Theorem of Sym. Fnc. Thry.]
    Every symmetric function can be written uniquely in the form $\sum_{\la}c_\la e_\la$ with $c_\la\in\bQ$. 
\end{Th}

There are at least two proofs if not more of this fact. The first comes from Maria Gillespie's blog which Mark Haiman presented to her. 

\begin{ptcbp}%http://www.mathematicalgemstones.com/gemstones/opal/the-fundamental-theorem-of-symmetric-function-theory/3/
    It suffices to prove the transition matrix between $m$ and $e$ is invertible.
\end{ptcbp}

For proof 2 read \cite{StanleyEnum2} pg. 290. Proof 3 in another Maria post %http://www.mathematicalgemstones.com/gemstones/opal/addendum-an-alternate-proof-of-the-ftsft/

\section{Day 5|20230130}

\begin{Ej}
Compute $\om(s_{(3,1)})$.
\end{Ej}

\begin{ptcbr}
We have that 
%$$s_{(3,1)}=m_{(3,1)}+\young{112,2}+\young{112,3}+\young{113,2}+\young{123,4}+$$
By Jacobi-Trudi 
$$s_{(3,1)}=\det\twobytwo{h_3}{h_4}{1}{h_1}=h_{(3,1)}-h_4.$$
Using the omega involution, we get 
%$$\om(s_{(3,1)})=e_{(3,1)}-e_4=s(\young{~,~,~~}).$$
\end{ptcbr}

Recall that $\om: h_n\otto e_n$, $\om p_k =(-1)^{k-1}p_k$. We have the following questions, where do $m$ and $s$ map to? Also 
$$\braket{m}{h}=\dl,\ \braket{p}{p/z}=\dl,$$
but what are $e$ and $s$ dual to?

\begin{Def}
    We call $\om m_\la = f_\la$ the \term{forgotten basis}.
\end{Def}

There's not much we could say about them, they are not Schur positive and there's no patterns. 

\subsubsection{Dual to $e$}

Recall $\om$ is an isometry, so $\braket{\om f}{\om g}=\braket{f}{g}$, so
$$\braket{e_\la}{?}=\braket{h_\la}{\om ?}=\dl_{\la\mu}.$$
Since $\braket{h}{m}=\dl$, then applying $\om$ again we get that $\braket{e_\la}{f_\mu}=\dl_{\la\mu}$.

\subsubsection{RSK algorithm}

We want to show two things:
$$\om s_\la=s_{\la^\sT},\ \braket{s_\la}{s_\mu}=\dl_{\la\mu}.$$

\begin{Prop}
    It holds that 
    $$\sum_{\la}s_\la(\un x)s_\la(\un y)=\Om=\sum_{\la}m_\la(\un x)h_\la(\un y)$$
\end{Prop}

\begin{ptcbp}
    The sum on the left is 
    $$\sum_{(S,T)SSYT}x^Sy^T$$
    so we will study pairs $(S,T)$ of SSYT of the same shape to show that they're equal to the sum on the right. 
\end{ptcbp}

algorithm: process of doing the bijection.\par 
The RSK bijection takes a pair $(S,T)$ of SSYT of the same shape and it maps it to ``two-line arrays'' of length $n$. 

\begin{Def}
    A \term{two-line array} is a matrix in $\cM_{2\x n}(\bZ_{\geq 0})$ such that 
    \begin{enumerate}[i)]
        \itemsep=-0.4em
        \item The bottom row is weakly increasing.
        \item If $b_i=b_{i+1}$, then $a_{i}\leq a_{i+1}$, where $a$'s are the top row and $b$'s the bottom row.
    \end{enumerate}
\end{Def}

\begin{Ex}
    Consider the matrix 
    $$\begin{pmatrix}
        1&1&2&1&4&2&3&1&2\\
        1&1&1&2&2&3&3&4&4
    \end{pmatrix}$$
    Within ``blocks'', there is a weak increment. From right-to-left we will find a pair of SSYT. We will ``insert'' top row letters from left-to-right.
    \begin{enumerate}
        \item Place 1st letter $\young(1)$
        \item For each letter, if it can go at the end of last row, put it there 
        $$\young(11)\leftarrow 2,\ \young(112)\leftarrow 1$$
        but one can't go after 2.
        \item Otherwise if inserting $b_1$, let $c$ be the leftmost $>b$, ``bump $c$'', then insert $c$ into the next row. 
        $$\young(111,2)$$
    \end{enumerate}
    For the bottom row, place in a new square at each step to form a ``recording tableau''. The recording tableau always matches the shape of the insertion one. The first three steps lead to $\young(111)$ in the recording one. But in the fourth step we get $\young(111,2)$. The next step leads us to 
    $$\young(1114,2),\quad \young(1112,2)$$
    then in insertion, 2 bumps 4 and 4 doesn't bump 2 on next row, so we get 
    $$\young(1112,24),\quad \young(1112,23)$$
    The three is no problem so 
    $$\young(11123,24),\quad \young(11123,23)$$
    then the next one bumps out the 2, the 2 bumps the 4 on the second row to get 
    $$\young(11113,22,4),\quad \young(11123,23,4)$$
    Finally 
    $$\young(11112,223,4),\quad \young (11123,234,4).$$
\end{Ex}

Why do we get SSYT. The insertion tableau gives us the question, can we make a column non-increasing? No, we are always bumping something bigger. Imagine we bump $c>b$ with $b$, then $c$ replaces something that goes to the left.
$$\young(\leq bc,~~,~)\To\young(~b~,~d,~)$$
and $d>c$ so it bumps something else. The recording tableau is also a SSYT. Let us prove it. 

\begin{Lem}[Key Lemma 1]\label{lemma-key-lemma-SSYT}
    The insertion path (sequence of squares that are bumped) moves up and weakly left. 
\end{Lem}

\begin{Lem}[Key Lemma 2]\label{lemma-consec-inserts}
If $a\leq b$ and $T$ is a SSYT, computing 
$$T\leftarrow\young(a)\leftarrow\young(b),$$
the intersection path of $a$ in $T$ lies strictly left of the intersection path of $b$ in $T\leftarrow\young(a)$.
\end{Lem}

\begin{ptcbp}
    We will do induction on the rows with an example.
\end{ptcbp}

\begin{Ex}
    Consider 
    $$\young(111223,22334,3355,44)$$
    Inserting $1$ we bump the 2, then the 3 and finally the 5. We get 
    $$\young(111o23,22t34,33t55,44f)$$
    so inserting the 2 we bump 3,4,5. And they will be to the side of the last sequence. 
\end{Ex}

\section{Day 6| 20230201}
\begin{Ej}
    Apply RSK to $\begin{pmatrix}
        3&2&4&1&5\\1&2&3&4&5
    \end{pmatrix}$
\end{Ej}

\begin{ptcbr}
    We get 
    $\young(145,2,3),\quad \young(135,2,4)$.
\end{ptcbr}

Notice that we got STANDARD Young tableau. So to prove it's a bijection we will begin with all different numbers.

\begin{Lem}
    The RSK bijection is a bijection between pairs of standard Young tableaux of the same shape and ``permutations'' ($2\x n$ matrices whose rows are permutations.)
\end{Lem}

To prove it's a bijection we will find an inverse by reversing the process. Look at the recording tableau, we will bump out the largest number. We will take $S$ as the recording tableau. Then we start with the spot on $S,T$ which corresponds to largest label in S.
\begin{itemize}
    \item If $b$ is the item in such a square we ``un-bump'' it.
    \begin{itemize}
        \item If in bottom row, just remove.
        \item Else, let $c$ be the rightmost entry in row below $b$ that is less than $b$. Then replace $b$ with $c$ and repeat the process with $c$ until the letter that is removed is done by the just removing it. 
    \end{itemize}
    Then we add the two letters to the matrix from right-t-left.
\end{itemize}

With the original tableau we remove the $5$ and the $5$ to get 
$$\young(14,2,3),\quad \young(13,2,4)$$
then the 4 indicates that in $T$ we must ``un-bump'' the 3. The three un-bumps the 2, the 2 to the 1 so that we get 
$$\young(24,3),\quad \young(13,2).$$
Now we get the matrix $\begin{pmatrix}
    x&x&x&1&5\\x&x&x&4&5
\end{pmatrix}$ and removing the 3 from $S$ just removes the 4 from $T$ as it is in the bottom row.\par 
Now as this two sets are in bijection, this means that they have the same size.

\begin{Cor}
    Let $f^\la$ be the number of standard Young tableau of shape $\la$. Then 
    $$\sum_{\la\vdash n}(f^\la)^2=n!.$$
\end{Cor}

We will generalize one step at a time. Let us now assume that $T$ is semi-standard. On the matrix, we will have that the top row is now random, but the bottom row is still from $1$ to $n$. 

\begin{Lem}[Schensted]
    There is a bijection between $(S,T)$, $S$ is standard, $T$ is SSYT, and words of length $n$.
\end{Lem}

\begin{Ex}
    Consider the matrix $\begin{pmatrix}
        2&1&3&1&3\\1&2&3&4&5
    \end{pmatrix}$ which returns the two Young tableau 
    $$\young(113,23),\quad \young(135,24).$$
\end{Ex}

The proof of the inverse is similar but when un-bumping, we must bump the rightmost entry \emph{strictly} smaller than $b$. But we don't need this, we will do it more creatively.

\begin{Def}
    Suppose $T$ is a Young tableau. Then 
    \begin{enumerate}[i)]
        \itemsep=-0.4em
        \item The \term{reading word} of $T$ $\text{rw}(T)$ is the concatenation of rows from top to bottom.
        \item The \term{standarization} of an SSYT $T$, $\text{std}(T)$, is the unique    SYT with same relative order of entries, ties broken with ``reading order''.
        \item The standarization of a word is similar
       \end{enumerate}
\end{Def}

In the previous example, the reading word is 
$$\young(113,23)\to 23113.$$
The standarization are as follows:
$$\young(113,23)\to \young(125,34),\quad 23113\to34125.$$
We can standarize the matrix 
$$\begin{pmatrix}
    2&1&3&1&3\\1&2&3&4&5
\end{pmatrix}\to\begin{pmatrix}
    3&4&1&2&5\\1&2&3&4&5
\end{pmatrix}$$
and this matrix corresponds to the pair $(S,T)$ where $T$ is $\young(125,34)$. In essence, the following diagram commutes
\begin{figure}[h]
    \centering
    % https://tikzcd.yichuanshen.de/#N4Igdg9gJgpgziAXAbVABwnAlgFyxMJZABgBpiBdUkANwEMAbAVxiRAAoBlUgFQEoQAX1LpMufIRQBGclVqMWbAExSAzGqEiQGbHgJEyUufWatEHbjwDkA4aN0SiMo9ROLz6gCxKArELkwUADm8ESgAGYAThAAtkhkIDgQSErUABYwdFBIYEwMDK4KZiBwONnUDHQARjAMAApiepIgkVhBaTiaEdFxiDKJyYiqdiBRsUiq1EkphaZsAEqcANJdoz1I-dOICW7FiysV1bUNDvrmre2dghSCQA
\begin{tikzcd}
    {(S,T)} \arrow[d, "std"'] & 21313 \arrow[d] \arrow[l, "RSK"'] \\
    {(S,T')}                  & 31425 \arrow[l, "RSK"]           
    \end{tikzcd}
\end{figure}

\begin{Def}
    Given a content $\mu=(\mu_1,\dots,\mu_k)$ with $\sum\mu_k=n$ (not nec. partition). Then the de-standarization with respect to $\mu$ of a SYT $T$ is a $SSYT$ $T'$ such that $\text{std}(T')=T$.
\end{Def}

In this case 
$$\young(125,34)\xrightarrow[\text{std}^{-1}(2,1,2)]{}\young(113,23).$$

Recall now lemma \ref{lemma-consec-inserts} about consecutive insertions.

\subsubsection{The Full RSK}

We are now going to prove that there is an inverse to the original RSK function. Consider the following example 
$$\begin{pmatrix}
    1&1&2&1&4&2&3&1&2\\
    1&2&3&4&5&6&7&8&9
\end{pmatrix}\to \young(11112,223,4),\quad \young(12357,469,8)$$
The matrix $\begin{pmatrix}
    1&1&2&1&4&2&3&1&2\\
    1&1&1&2&2&3&3&4&4
\end{pmatrix}$
can be standarized to our word matrix. Then the table $\young(11123,234,4)$ also standarizes to the word table. 

\section{Day 7| 20230203}

\begin{Ej}
    Expand $h_{(3,2)}$ in Schur basis.
\end{Ej}

\begin{ptcbr}
    This is $s_{(3,2)}+s_{(4,1)}+s_{(5)}$.
\end{ptcbr}

Recall that $(s_\la)$ form an orthonormal basis and $m$ and $h$ are dual basis. This means that if $f$ is a symmetric function then 
$$f=\sum_\la c_\la s_\la\To c_\la=\braket{f}{s_\la},\ f=\sum_\la a_\la m_\la\To a_\la=\braket{f}{h_\la}.$$
Lets suppose now that $f$ is any homogenous symmetric function. We will calculate the coefficient of $s_\la$ in an $h_\mu$ expansion:
$$\braket{h_\mu}{s_\la}=\braket{s_\la}{h_\mu}$$
and we can interpret this as the coefficient of $m_\mu$ in $s_\la$. This amount is precisely the Kostka coefficient $K_{\la\mu}$. Thus we have the formula $h_\mu=\sum_\la K_{\la\mu}s_\la$.

\subsection{Properties of the Schur functions}

We wish to show that $\braket{s_\la}{s_\mu}=\dl_{\la\mu}$ and $\om s_\la=s_{\la^\sT}$.

\begin{Prop}
    $\sum_\la s_\la(\un{x})s_\la(\un{y})=\sum_\la m_\la(\un{x})h_\la(\un{y})$
\end{Prop}

\begin{ptcbp}
    Expanding the sum on the left we obtain 
    $$\sum_\la s_\la(\un{x})s_\la(\un{y})=\sum\la\left(\sum_{T\in SSYT(\la)}x^T\right)\left(\sum_{S\in SSYT(\la)}y^S\right)=\sum_{(T,S),\ SSYT\text{same shape}}x^Ty^S$$

    This is basically an RSK pair and this correspond to two-line arrays, so this sum could be the same as summing over them. Thus this is  
    $$\sum_{2\text{line arrays}}x_{a_1}\dots x_{a_n}y_{b_1}\dots y_{b_n}.$$
We will now find the coefficient of $m_\la(\un y)$ in this expansion and show that it is $h_\la(\un x)$\par 
What are all the ways to obtain $y_1^{\la_1}\dots y_k^{\la_k}$?
$$\begin{pmatrix}
    a_1^{(1)}&\dots&a_k^{(1)}&a_1^{(2)}&\dots&a_k^{(2)}&\dots\\
    1&1&1&2&2&2&\dots
\end{pmatrix}$$
And note that $a_1^{(i)}\leq\dots\leq a_{\la_i}^{(i)}$ for all $i$, so the coefficient is 
$$\sum_{(a^{(i)}) valid tuples}x_{a_1^{(1)}}\dots x_{a_{\la_k}^{(k)}}$$
but this factors as 
$$\prod_{i=1}^k\sum_{a_1^(i)\leq\dots\leq a_{\la_k}^{(i)}}x_{a_1^{(i)}}\dots x_{a_{\la_k}^{(i)}}.$$
We can split this because the choices are independent of the blocks and then multiply the functions together. The last term is $h_{\la_i}$ and the product is $h_\la.$
\end{ptcbp}

If $(T,S)$ RSKs inverse to $\twobythree{1}{3}{2}{1}{1}{2}$ then $x^Ty^S$ is $x_1x_3x_2y_1y_1y_2$.

\begin{Cor}
    $\om s_\la=s_{\la^\sT}$. 
\end{Cor}

\begin{ptcbp}
    It suffices to show $\braket{s_{\la^\sT}}{e_\mu}=K_{\la\mu}$ because $\braket{s_\la}{h_\mu}=K_{\la\mu}$ which implies that $\braket{\om s_\la}{e_\mu}=K_{\la\mu}$.\par 
    In other words, we wish to show that the coefficient of $s_\la$ in $e_\mu$ is $K_{\la^\sT\mu}$, the number of $SSYT$ shape $\la^\sT$, content $\mu$.\par 
\red{CONT}
\end{ptcbp}

\subsection*{Pieri Rule}

\begin{Def}
    A \term{skew shape} is a diagram formed by subtracting a smaller Young diagram from a larger one.\par 
    A \term{horizontal strip} is a skew shape where no two boxes are in the same column. Similar a \term{vertical strip} doesn't have boxes in the same row.
\end{Def}

\begin{Ex}
    Suppose $\la=(5,4,4,1)$ and $\mu=(4,2,2)$. Then 
    $$\la=\young(~,~~~~,~~~~,~~~~~),\quad \mu=\young(~~,~~,~~~~)$$
    so $la/\mu$ is INSERT DIAG.
    Not horizontal nor vertical.
\end{Ex}

In a Young tableau, the biggest number forms a horizontal strip, so in general Young tableaux are made up of horizontal strips.
$$\young(4,344,2233,111234).$$

\begin{Th}[Pieri]
    Let $r\in\bN$, then 
    $$e_rs_\la=\sum_{\rho/\la\text{vert. strip size }r}s_\rho$$ 
    $$h_rs_\la=\sum_{\rho/\la\text{horiz. strip size }r}s_\rho$$
\end{Th}

This is basically all the ways to fill up the shapes.

\begin{ptcbp}
    $$h_rs_la=s_{(r)}s_\la=\left(\sum_{T\in SSYT((r))}x^T\right)\left(\sum_{S\in SSYT(\la)}x^S\right)$$
\end{ptcbp}

\begin{Ex}
    $h_3s_{(3,1)}$ is $x^Tx^S$ is inserting the boxes of $T$ one at a time in $S$. 
    $$\young(3,123)\leftarrow \young(112)=\young(3,23,1112)$$
    so by \ref{lemma-key-lemma-SSYT} about insertion path, the new squares are a horizontal strip which is the $s_\rho$ in the Pieri rule. Unbumping we recover \red{something}.
\end{Ex}

\section{Day 8| 20230206}

\begin{Ej}
    Apply RSK to $82357146$ and $62235124$.
\end{Ej}

\begin{ptcbr}
    $$\young(8,2357),\young(2,1345)$$
    then $1$ bumps the 2, 2 bumps 8
    $$\young(8,257,1346),\young(6,278,1345)$$
    The next one standarizes to the last string. The same recording table but we get for insertion 
    $$\young(6,235,1224).$$
\end{ptcbr}

\subsection{Consequences of RSK}

We will talk about increasing and decreasing subsequences.

\begin{Def}
    A longest increasing subsequence of a word $w\in\bN^{n}$ is a subsequence $w_{i_1}\leq\dots\leq w_{i_\l}$ with $i_1<\dots<i_\l$ such that $\l$ is as large as possible. We will write $\l(w)$ to be the length of the longest increasing subsequence.\par 
    A longest decreasing subsequence of a word is 
    $w_{i_1}>\dots>w_{i_d}$ with $i_1<\dots<i_d$. In this case $d(w)$ is the longest decreasing.
\end{Def}

\begin{Ex}
    In the case of $82357146$, we have $2357,2356,146,2346$. Notice that this is the length of ?? of the Young tableau. For decreasing we have $821,831,\dots$, the height of the Young tableau is the longest decreasing subsequence.
\end{Ex}

\begin{Th}\label{th-length-long-dec-inc-word}
    Suppose $w$ is a word, $S=\text{ins}(w)$ is the insertion tableau through RSK and $\la=\text{sh}(S)$ is the shape of the table. Then $\l(w)=\la_1$ and $d(w)=\la_1^{\sT}$. 
\end{Th}

To prove this we will develop some tools.

\begin{Lem}\label{lem-reading-word}
    For a tableau $T$, $\text{ins}(\text{rw}(T))=T$.
\end{Lem}

The reading word of $\young(8,257,1346)$ is $82357146$ which inserts to the same table precisely.

\begin{Rmk}
    The column reading word also works! For this table it's $82153746$. We get a bunch of decreasing subsequences. $821$ creates the first column by bumping, then $53$ creates the second column and so on. 
\end{Rmk}

Let's analyze the longest increasing subsequence of the reading word. Clearly we can get the bottom row as a longest subsequence, but looking in the reading order we need to go to the right. Going down decreases!

\begin{Lem}
    If $\la=\text{sh}(T)$ then $\l(\text{rw}(T))=\la_1$ and $d(\text{rw}(T))=\la_1^\sT$.
\end{Lem}

\begin{ptcbp}
    Given an entry $a\in T$, let $b\in T$ such that $a<_{\text{ro}}b$. Then $b$ is in a column to the right of $a$, this means that 
    $$\l(\text{rw}(T))\leq \#\text{columns}=\la_1.$$
    The bottom row is an example of a subsequence where the length is achieved. So equality holds.
\end{ptcbp}

For decreasing it's equivalent. Now, how do we tell when two words have the same insertion tableau?

\begin{Ex}
    In the case of all permutations in $S_3$ we have that some are equivalent \red{FILL}
\end{Ex}

\subsubsection{Knuth equivalence}

\begin{Def}
    A \term{Knuth move} on a permutation swaps two letters $a,c$ if $a<b<c$ (reading order) and one of consecutive subsequences $acb,cab,bac,bca$ appears in the word.\par 
    Two words are \term{Knuth-equivalent} if they differ by a sequence of Knuth-moves.
\end{Def}

In the first case, $b$ is between $a,c$ and those are always together.

\begin{Prop}
    Knuth equivalence defines an equivalence relation on $S_n$. 
\end{Prop}

\begin{Th}
    Two words $\pi,w$ are Knuth-equivalent iff $\text{ins}(w)=\text{ins}(\pi)$.
\end{Th}

\begin{Ex}
    In size $4$, $1234$ is in its own class because we don't have any Knuth moves available. Same thing happens with $4321$.\par 
    Consider $1243$, if we apply Knuth moves we can get 
    \begin{itemize}
        \begin{multicols}{2}
            \itemsep=-0.4em
            \item $1423$
            \item $4123$
        \end{multicols}
    \end{itemize}
    All of these have the insertion tableau $\young(4,123)$ whose reading word is $4123$.\par 
    For the tableau $\young(24,13)$, its reading word is $2413$. Applying Knuth moves we get only $2143$, which is the column reading word.\par 
    The tableau $\young(34,21)$'s equivalence class also has size 2. 
\end{Ex}

\begin{Prop}
    If two tableau have the same shape, their equivalence classes have the same size. 
\end{Prop}

We are seeking to prove $\l(w)$ is invariant under Knuth moves. This will imply the theorem \ref{th-length-long-dec-inc-word} because once we know that things have the same insertion tableau and the reading word has the same longest increasing subsequence length.

\section{Day 9| 20230208}

\begin{Ej}
    Insert $f,g$ and then $c$ into 
    $$\young(k,eij,abdhl)$$
    and then $f,c$ and then $g$.
\end{Ej}

\begin{Ex}
    The Knuth equivalence class of words whose insertion tableau is 
    $$\young(34,125).$$
    The reading word is $34125$ and we can Knuth-move it. The $341$ can switch into $314$ (this has the form $bac$). From that one we can switch $2$ and $5$ to get $31452$. Once again with $314$ we get $34152$ and $34512$.\par 
    In total we have $5$ elements.
\end{Ex}

\begin{Prop}
    The size of the Knuth equivalence class whose insertion tableau is $T$ with shape $\la$ is $\#SYT(\la)$.
\end{Prop}

\begin{ptcbp}
    We have one permutation in the Knuth equivalence class for every recording tableau $S$ that can be paired with $T$.
\end{ptcbp}

The Knuth equivalence class of $\young(34,125)$ can be identified by RSK with the pairs $(T,S)$ and $S$ varies through all SYT of corresponding shape.\par
Also, recall that by that hook-length formula we have that 
$$\#SYT(\la)=\frac{|\la|!}{\prod_{\text{hooks}\subseteq T} \text{size hooks}}.$$

\begin{Th}
    Two permutations $\pi, w$ have the same insertion tableau if and only if $\pi$ is Knuth-equivalent to $w$.
\end{Th}
%BUMP: QUITAR EL PRIMERO MAS GRANDE Y PARRIBA
\begin{ptcbp}
By induction on the length, we can assume $\pi, w$ differ by a single Knuth-move on the last $3$ letters. We separate into cases:
\begin{enumerate}[i)]
    \itemsep=-0.4em
    \item Want 
    $$T'\leftarrow b\leftarrow c\leftarrow a=T'\leftarrow b\leftarrow a\leftarrow c$$
    Note that $\ttt{IP}(b)<\ttt{IP}(c)$ by lemma \ref{lemma-consec-inserts} of consecutive insertions and $\ttt{IP}(a)$ is \emph{weakly left} of $\ttt{IP}(b)$ from which holds $\ttt{IP}(a)$ is strictly left of $c$'s. So we can switch order.
    \item In the other case  we want
    $$T'\leftarrow c\leftarrow a\leftarrow b=T'\leftarrow a\leftarrow c\leftarrow b.$$
    $\ttt{IP}(a)$ is \emph{weakly left} of $c$'s. If it's \emph{strictly}, then we can switch, but otherwise the insertion paths of $a$ and $c$ collide. \red{CHECK NOTES}
\end{enumerate}
Now on the other direction, we wish to show that two permutations with the same insertion tableau are Knuth-equivalent.\par 
It suffices to show that they are Knuth-equivalent to the reading word. By induction of the size of the word, suppose $\text{ins}(w')=T'$. Then $w'\sim\text{rw}(T')$ for $w'$ of length $n-1$.\par 
Let $w\in S_n$ with $b=w_n$. If $T'=\text{ins}(w_1,\dots,w_{n-1})$, by induction $w_1\dots w_{n-1}\sim\text{rw}(T')=(first\ row)\dots(last\ row)$. 
\end{ptcbp}

\begin{Ex}
    For the second case consider the table 
$$\young(389,147)$$
and we insert $6,2$ then $5$ but then $2,6$ and then $5$. In the first case, \red{DUNNO}\par 
In the second case consider 
$$T'=\young(6,47,1258)$$
\end{Ex}

\section{Day 10| 20230210}

\begin{Lem}
    The length of the longest increasing subsequence, $\l(w)$ is invariant under Knuth moves.
\end{Lem}

\begin{ptcbp}
    Given an increasing subsequence, if a Knuth move changes two of its entries $a<c$, we have two cases:
    \begin{enumerate}[i)]
        \itemsep=-0.4em
        \item Either $b$ is to the right of $ac$ so we get 
        $$\dots acb\dots d\dots\to\dots cab\dots\dots d\dots$$
        then replacing $c$ with $b$ gives an increasing subsequence of same length in a new word $a<b<c$ by assumption so $\un a<\un b<c<\un d$ where $d$ is the next element of the subsequence after $c$.
        \item We have $b$ to the left so we have 
        $$\dots bac\dots d\dots\to\dots bca\dots d\dots$$
        and the same proof shows that replacing $a$ and $b$ gives s anew subsequence and a new subword of the same length.
    \end{enumerate}
\end{ptcbp}

Knuth equivalence is natural when it comes to increasing and decreasing subsequences. With the lemmas we have, we can now prove that $d$ is the height of the insertion tableau.

\begin{Rmk}
    Dual equivalence is finding $3$ values $acb$ so we can switch $bca$. For example 
    $$615342\to 625341\to 624351$$
    and dual equivalent words have the same \emph{recording tableau}.
\end{Rmk}

The result we've been aiming for is 
$$\l(w)=\text{width of }\text{ins(w)}=\la_1$$

\begin{ptcbp}
    Suppose $T=\text{ins}(w)$ with $\la=\text{sh}(T)$. Then $w\sim\text{rw}(T)$, by the previous lemma we have 
    $$\l(w)=\l(\text{rw}(T))=\la_1$$
    and the last equality comes from Monday class. \red{Add references}
\end{ptcbp}

For decreasing subsequences we have the same argument. To wrap it up we have a theorem we have a theorem from Stanley \cite{StanleyEnum2}:

\begin{Th}
    A longest $i$-chain of increasing subsequences of $w$ consists of:
    \begin{itemize}
        \item An increasing subsequence $s_1$ of $w$.
        \item An increasing subsequence $s_2$ of $w\less s_1$.
        \item (\dots)An increasing subsequence $s_i$ of $w\less s_1\dots s_{i-1}$.
    \end{itemize}
    Then the length of the longest $i$-chain is $\la_1+\la_2+\dots+\la_i$.
\end{Th}

\subsection{Jeu de taquin}

%https://encyclopediaofmath.org/wiki/Jeu_de_taquin
%READ

The phrase \emph{jeu de taquin} means ``teasing game''. This process is equivalent to RSK and insertion. As motivation, inserting $\emptyset\leftarrow w$ and then insert $\rho$ and finally $\pi$, then this is the same as 
$$w\leftarrow\text{rw}(\text{ins}(\rho)\leftarrow \pi).$$
This means that there's some \emph{associativity} in this operation. 

\begin{Def}
    A \term{skew-SSYT} is a filling of the boxes of a skew shape (skew Ferrers diagram) with $n\in\bN$ such that rows are weakly increasing and columns are strictly increasing.
\end{Def}

This is analogous to SSYT, so let's see an example

\begin{Ex}
    $(9,9,5,5,3)/(7,6,3,3)$, but the initial partition could've been $(10,10,6,6,4)$ or $(100,9,9,5,5,3)$. 
    $$\young(o,224o,::x34,:::13o,:::::x223,::::::x11o)$$
\end{Ex}

Notice that all rows and columns are adjacent, and there are no leftover squares.

\begin{Def}
    A \term{corner} of a Young diagram $\mu$ is a square of $\mu$ at the top of its column, right of its row.\par 
    An \term{inner corner} of $\la/\mu$ is a corner of $\mu$. While an \term{outer corner} of $\la/\mu$ is a square outside $\la$ that is just above its column (poss. 0) just right of a row (poss. 0).
\end{Def}

\begin{Rmk}
    Notice that adding an outer corner makes a valid shape for a partition.
\end{Rmk}

The JdT game is defined through the following moves
\begin{Def}
    An \term{inner slide} into an inner corner $x$ of a SSYT $T$ of skew-shape $\la/\mu$ is given by the following process:
    \begin{enumerate}[i)]
        \itemsep=-0.4em
        \item Compare squares $a,b$ in the following shape 
        $$\young(a,xb)$$
        If $a\leq b$ or there's no $b$, slide $a$ down. Else slide $b$ left.
        \item Repeat for the new location of $x$ until it becomes an outer corner.
    \end{enumerate}
\end{Def}

\begin{Ex}
    In the previous example we can consider 
    $$\young(:::::x223,::::::x11o)$$ and slide the $1$ because if we slide $2$ it's no longer SSYT. But then we get an empty square, so we keep going until it's a valid shape. The end result is 
    $$\young(:::::x22o,::::::113o)$$
    For a bigger example consider 
    $$\young(2445,:3336,:1223,:x112)\to\young(244o,:3356,:2233,:1112)$$
\end{Ex}

\begin{Rmk}
    A slide sends an SSYT to an SSYT. A case like 
    $$\young(~3,4x5)$$
    because there should be an entry there $\leq 3$ and $>4$. 
\end{Rmk}

We can continue applying the process to the following inner corners to get a SSYT. 

\begin{Def}
    The \term{rectification} of a skew SSYT is the result of performing JDT slides until we don't have inner corners left. We say that the shape is \term{straight}.
\end{Def}

\begin{Rmk}
    The rw of the skew-shape is the same as the rectification.
\end{Rmk}

\section{Day 11| 20230213}

Recall we have talked about the Jeu de Taquin. We observed that JDT slides send skew SSYT to other skew SSYT. To show compatibility with Knuth-equivalence, we want will require a more general definition of reading word because for example in the middle of a JDT we may have 
$$\young(3478,::2:4,::1133).$$

\begin{Def}
    A \term{reading word} of any labeled set of boxes in the $1^{\text{st}}$ quadrant is formed by reading the rows from top to bottom L to R with each row.
\end{Def}

\begin{Lem}
    If a skew SSYT $S$ is obtained from another skew SSYT $T$ by a sequence of JDT slides, then $\text{rw}(S)\sim_K\text{rw}(T)$.
\end{Lem}
\begin{ptcbp}
    Assume $S,T$ differ by one inner-slide. There are a couple of cases, we'll show that at each step of the slide the Knuth equivalence class of the reading word is unchanged. (Even when we haven't finished the slide.)\par 
    The first case is when we do a horizontal slide 
    $$\young(a,xb)\to \young(a,bx)$$
    and nothing happens here because the reading word is still $ab$. The interesting case is the vertical slide.\par 
PROOF BY EXAMPLE
\end{ptcbp}

\begin{Ex}
    Consider the tableau 
    $$\young(stuff,12567T,::34x89)\to\young(1256xT,::34789)$$
    the reading word changes from $12567T3489$ to $1256T34789$. We will apply Knuth moves to the reading word of the original tableau.\par 
    We need an algorithm to guarantee that we get from one point to another. It suffices to consider the subword $567T348$ on the smaller window 
    $$\young(567T,34x8)$$
    Thinking in steps we want to move the $3$ backwards past the $7$, then $4$ and finally pull the $10$ back. We have 
    $$567T348\to 5673T48$$
    Notice that $6>3$ because $6>4>3$ and it's also less than $7$, there's still something still past the $7$ which we can use to move the $3$. We get 
    $$5637T48\to56374T8$$
    We use the $5$ to pull the $3$ out of the way, once again the $5$ is there due to semi-standardness. We get 
    $$53674T8\to 53647T8$$
    and to move the $T=10$ we use the $8$ which is below $10$ due to semi-standardness. Applying a Knuth  move with $7T8$ we obtain 
    $$5364T78\to 5634T78\to563T478\to 56T3478$$ 
\end{Ex}

\begin{Rmk}
    If we had more \emph{stuff} we would wave to take a longer subword.
\end{Rmk}

We said the rectification was the end goal of a JDT, with this in hand we can \emph{well}-define it. 

\begin{Def}
    The \term{rectification} of a SSYT is formed by performing inner JDT slides until we have a straight shape. 
\end{Def}

This is well defined because no matter the order of slides, the reading word of the rectification is equivalent to the reading word of the original tableau.\par 
As the Knuth equivalence determines the insertion tableau (rect(T)=ins(rw(T))) (knuth class=ins tableau thm.) So putting it all together we see it works.

\begin{Ex}
    Rectify the tableau 
    $$\young(24,:15,::3)\to\young(2,145,::3)\to\young(2,14,:35)\to\young(24,135).$$
    However we can also do 
    $$\young(24,:15,::3)\to\young(2,:45,:13)\to\young(245,:13)\to\young(24,135).$$
    The Knuth equivalence of the reading words of all tableau is the same! The other method is to take the reading word of the original tableau $24153$ and then insert it to the corresponding tableau.
\end{Ex}

Now we can completely replace insertion with rectification because we can make any word with skew-tableau.

\begin{Cor}
    The rectification of the skew tableau
    %$$\young(w_1,:w_2,::\ddots,:::w_n)$$
    where $w$ is any word is $\text{ins}(w)$.
\end{Cor}

\begin{Ex}
    Consider the tableau 
    $$\young(5,467,1245,::::3),$$
    we will rectify it and see it is the same as bump-inserting the $3$ into the tableau.
    We get 
    $$\young(5,467,1245,::::3)\to\to\young(5,467,124,::35)\to\to\young(56,447,1235)$$
    \red{DO THE SLIDING}
\end{Ex}

Then doing the diagonal process is intuitively inserting by this process.

\begin{Def}
    We define the product of two tableau $T,U$ as the rectification of the skew tableau formed by connecting the lower right corner of $T$ to the upper left of $U$.\par 
    Equivalently
    $$T\circ U=\text{rect}(T\leftarrow\text{rw}(U)).$$
    This gives us an associative operation because of the Knuth-equivalence. In consequence the set of tableaux is a monoid, as the identity element is the empty tableau.\par 
    We define it as the \term{Plactic monoid}, the set of SSYT's of straight shape with $\circ$. 
\end{Def}

It's interesting to look at the Plactic monoid in terms of words as well. 

\begin{Def}
    The Plactic monoid is the $\set{\text{words}}/\sim$ with the concatenation of words as the operation and $\sim$ is Knuth-equivalence.
\end{Def}

\begin{Ex}
    If $w=\bonj{2131},v=[2213]$, then 
    $$wv=\bonj{21312213}=\bonj{21132213}.$$
\end{Ex}

For the next class we will talk about skew Schur functions. We will build up to writing skew functions in terms of the ordinary ones.

\section{Day 12| 20230215}

\subsection{Skew Schur functions}

\begin{Def}
    $$s_{\la/\mu}=\sum_{\ast}x^T$$
    where $x^T=x^{\# 1's}x^{\# 2's}\dots$. This is still a symmetric function by the same proof as for $s_\la$.
\end{Def}

\begin{Ex}
    Compute $s_{(3,2)/(1)}$ in terms of $m$ basis \red{PHOTO}
\end{Ex}

But instead we can see that this function is also $s_{(2,2)}+s_{(3,1)}$. It turns out that skew Schur functions are Schur positive. Recall that this means that in the Schur basis expansion, all of its coefficients are positive integers.

\begin{Th}
    $s_{\la/\mu}$ is Schur-positive,
    $$s_{\la/\mu}=\sum_{\nu\vdash|\la|-|\mu|}c^{\la}_{\mu,\nu}s_\nu$$
    The coefficients are called the Littlewood-Richardson coefficients.
\end{Th}

We can use the Littlewood-Richardson coefficients to count certain Young tableaux. However another way to compute coefficients which uses a similar rule is the \emph{Knutson-Tao puzzles}.

\subsection{Littlewood-Richardson rule}

\begin{Def}
    A word $w$ of positive indices is (reverse) ballot, \term{Yamanouchi}, or lattice if every suffix $w_iw_{i+1}\dots w_n$ has partition content. This is that reading the word from right-to-left the number of $1's$ is greater the $2's$ and so on. 
    $$\#1's\geq\#2's\geq\#3's\geq\dots$$
\end{Def}

\begin{Ex}
    Consider the word $341231211$, this is Yamanouchi, while $21433231211$ is not Yamanouchi.
\end{Ex}

\begin{Def}
    A skew tableau is called Littlewood-Richardson if its reading word is a Yamanouchi word.
\end{Def}

\begin{Th}
    The Littlewood-Richardson coefficient is the number of Littlewood-Richardson tableaux of shape $\la/\mu$ and content $\nu$.
\end{Th}

\begin{Ex}
    Let us find some Littlewood-Richarson coefficients. Consider 
    $$\la/\mu=\young(~~,:~~),\ \nu=(2,2)$$
    so we need to find L-R tableaux of shape $\la/\mu$ with content $(2,2)$ (2 ones and 2 twos). The only possibilities are 
    $$\young(22,:11),\word{and}\young(12,:12)$$
    and the latter's reading word is $1212$ which is not Yamanouchi because it ends in a 2 and not a 1.\par 
    Let us now find the number of L-R tableaux with shape 
    $$\young(~~,~~,::~~~,::::~~)$$
    and content $(4,3,2)$. We have the following tableaux
    $$\young(33,12,::122,::::11),\word{and}\young(33,22,::112,::::11)$$
    This means that 
    $$c^{(6,5,2,2)}_{(4,2),(4,3,2)}.$$
\end{Ex}

Notice that by proving this result, we immediately get that the skew Schur functions are Schur positive. We will use crystal-base theory. This comes from the representation theory of $\cU_{q}(\gsl_n)$.\par 
A crystal of tableau sorts the monomials into a graph, let us for example consider 
$$\young(2,11)$$

\section{Day 13| 20230217}

\subsection{Crystals on words}

Operating on words means we can operate on reading words and thus on tableau.

\begin{Def}
    For a word $w$ of 1's and 2's, we define the \term{raising operator} $E_1$ and \term{lowering operator} $F_1$ by:
    \begin{itemize}
        \itemsep=-0.4em
        \item Replacing all ones with right parenthesis and twos with left parenthesis.
        \item Then we pair off matching parenthesis.
        \item $E_1$ makes the first unmatched $2$ to a $1$ and $F_1$ the last unmatched $1$ to a $2$. %FLU12 EFU21
    \end{itemize}
\end{Def}
\begin{Ex}
    Consider the word
    $$112212111122212\to))(()())))((()($$
    Applying $E_1$ we get 
    $$112212111112212\to11221211111212\to112212111111211$$
    and applying once again we get the empty word because there's no more match. We can see that applying $F_1$ reverses this process. While applying $F_1$ to our original word several times we get 
    $$222212112222212$$
    before we get to the empty word.
\end{Ex}

\begin{Def}
    For a word $w\in\bZ^n_{\geq 0}$, then $E_i$ is formed looking at the $(i,i+1)$, treating them as $(1,2)$ and performing $E_1$. 
\end{Def}

This allows us to draw graphs on words where we connect after applying the operations.\par 
The reason they are called raising and lowering is because in terms of content, the raise and lower the content:
\begin{align*}
    222212112222212\to(4,11)\\
    112212111122212\to(8,7)\\
    112212111111211\to(11,4)
\end{align*}
This also correspond to weight spaces in representations of $\gsl_n$. 

\begin{Rmk}
    Recall the Lie algebra of $\SL_2$ is 
    $$\gsl_2=\set{A\in\cM_2\:\ \tr(A)=0}.$$
    This is an additive vector space with a Lie bracket, it's not closed under multiplication. The matrices with generate this space are 
    $$E=\twobytwo{0}{1}{0}{0},\quad F=\twobytwo{0}{0}{1}{0},\word{and}H=\twobytwo{1}{0}{0}{-1}.$$
    In general in $\gsl_n$, $E_i$ has a 1 on top of the $i^{\text{th}}$ position on the diagonal.
\end{Rmk}

\begin{Ex}
    Consider the word $111$ we get the following graph
    \begin{center}
        

\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300

%Straight Lines [id:da42089973349634247] 
\draw    (179,27.5) -- (152.41,54.09) ;
\draw [shift={(151,55.5)}, rotate = 315] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da3031105581540732] 
\draw    (176,126.5) -- (149.41,153.09) ;
\draw [shift={(148,154.5)}, rotate = 315] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da803008915658254] 
\draw    (124,78.5) -- (97.41,105.09) ;
\draw [shift={(96,106.5)}, rotate = 315] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da8767210663804941] 
\draw    (73,119.5) -- (46.41,146.09) ;
\draw [shift={(45,147.5)}, rotate = 315] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da11711889811973819] 
\draw    (126,172.5) -- (99.41,199.09) ;
\draw [shift={(98,200.5)}, rotate = 315] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da5343444040412961] 
\draw    (183,206.5) -- (156.41,233.09) ;
\draw [shift={(155,234.5)}, rotate = 315] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da8170158271849678] 
\draw    (153,84) -- (171.74,106.95) ;
\draw [shift={(173,108.5)}, rotate = 230.77] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da2307297886745664] 
\draw    (100,124) -- (118.74,146.95) ;
\draw [shift={(120,148.5)}, rotate = 230.77] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da7984622676548068] 
\draw    (46,169) -- (64.74,191.95) ;
\draw [shift={(66,193.5)}, rotate = 230.77] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da5520008445276355] 
\draw    (158,168) -- (176.74,190.95) ;
\draw [shift={(178,192.5)}, rotate = 230.77] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da1625762686635499] 
\draw    (97,213) -- (115.74,235.95) ;
\draw [shift={(117,237.5)}, rotate = 230.77] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da1026725922353392] 
\draw    (157,250) -- (175.74,272.95) ;
\draw [shift={(177,274.5)}, rotate = 230.77] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da4681112463331931] 
\draw    (375,37) -- (399.46,57.23) ;
\draw [shift={(401,58.5)}, rotate = 219.59] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da657993683720376] 
\draw    (347,41.5) -- (320.49,65.17) ;
\draw [shift={(319,66.5)}, rotate = 318.24] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da23694615966603938] 
\draw    (398,78.5) -- (332.64,124.35) ;
\draw [shift={(331,125.5)}, rotate = 324.95] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da6217535822776135] 
\draw    (338.5,80.5) -- (390.33,114.41) ;
\draw [shift={(392,115.5)}, rotate = 213.19] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
%Straight Lines [id:da6082139480648872] 
\draw    (300,144.5) -- (273.49,168.17) ;
\draw [shift={(272,169.5)}, rotate = 318.24] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

% Text Node
\draw (165,3.4) node [anchor=north west][inner sep=0.75pt]    {$111$};
% Text Node
\draw (122,63.4) node [anchor=north west][inner sep=0.75pt]    {$112$};
% Text Node
\draw (168,108.4) node [anchor=north west][inner sep=0.75pt]    {$113$};
% Text Node
\draw (126,153.4) node [anchor=north west][inner sep=0.75pt]    {$123$};
% Text Node
\draw (75,103.4) node [anchor=north west][inner sep=0.75pt]    {$122$};
% Text Node
\draw (16,150.4) node [anchor=north west][inner sep=0.75pt]    {$222$};
% Text Node
\draw (71,195.4) node [anchor=north west][inner sep=0.75pt]    {$223$};
% Text Node
\draw (184,195.4) node [anchor=north west][inner sep=0.75pt]    {$133$};
% Text Node
\draw (129,232.4) node [anchor=north west][inner sep=0.75pt]    {$233$};
% Text Node
\draw (188,270.4) node [anchor=north west][inner sep=0.75pt]    {$333$};
% Text Node
\draw (167,44.9) node [anchor=north west][inner sep=0.75pt]    {$F_{1}$};
% Text Node
\draw (164,143.9) node [anchor=north west][inner sep=0.75pt]    {$F_{1}$};
% Text Node
\draw (112,95.9) node [anchor=north west][inner sep=0.75pt]    {$F_{1}$};
% Text Node
\draw (61,136.9) node [anchor=north west][inner sep=0.75pt]    {$F_{1}$};
% Text Node
\draw (114,189.9) node [anchor=north west][inner sep=0.75pt]    {$F_{1}$};
% Text Node
\draw (171,223.9) node [anchor=north west][inner sep=0.75pt]    {$F_{1}$};
% Text Node
\draw (178,104.1) node [anchor=south west] [inner sep=0.75pt]    {$F_{2}$};
% Text Node
\draw (125,144.1) node [anchor=south west] [inner sep=0.75pt]    {$F_{2}$};
% Text Node
\draw (71,189.1) node [anchor=south west] [inner sep=0.75pt]    {$F_{2}$};
% Text Node
\draw (183,188.1) node [anchor=south west] [inner sep=0.75pt]    {$F_{2}$};
% Text Node
\draw (122,233.1) node [anchor=south west] [inner sep=0.75pt]    {$F_{2}$};
% Text Node
\draw (182,270.1) node [anchor=south west] [inner sep=0.75pt]    {$F_{2}$};
% Text Node
\draw (347,16.4) node [anchor=north west][inner sep=0.75pt]    {$121$};
% Text Node
\draw (401,59.4) node [anchor=north west][inner sep=0.75pt]    {$131$};
% Text Node
\draw (304,63.4) node [anchor=north west][inner sep=0.75pt]    {$221$};
% Text Node
\draw (301,120.4) node [anchor=north west][inner sep=0.75pt]    {$132$};
% Text Node
\draw (402,118.4) node [anchor=north west][inner sep=0.75pt]    {$231$};
% Text Node
\draw (254,177.4) node [anchor=north west][inner sep=0.75pt]    {$232$};
% Text Node
\draw (581,19.4) node [anchor=north west][inner sep=0.75pt]    {$211$};
% Text Node
\draw (548,61.4) node [anchor=north west][inner sep=0.75pt]    {$212$};
% Text Node
\draw (624,60.4) node [anchor=north west][inner sep=0.75pt]    {$311$};
% Text Node
\draw (546,124.4) node [anchor=north west][inner sep=0.75pt]    {$312$};
% Text Node
\draw (629,122.4) node [anchor=north west][inner sep=0.75pt]    {$213$};
% Text Node
\draw (526,181.4) node [anchor=north west][inner sep=0.75pt]    {$322$};
% Text Node
\draw (593,229.4) node [anchor=north west][inner sep=0.75pt]    {$323$};
% Text Node
\draw (648,183.4) node [anchor=north west][inner sep=0.75pt]    {$313$};
% Text Node
\draw (354,223.4) node [anchor=north west][inner sep=0.75pt]    {$332$};
% Text Node
\draw (430,186.4) node [anchor=north west][inner sep=0.75pt]    {$331$};


\end{tikzpicture}

    \end{center}

    Note that the words $121$ and $211$ both insert to 
    $$\ins(121)=\ins(211)=\young(2,11).$$
    Also look at the fact that we have listed all the words of length $3$. As an alternative definition, write all the words, match them by $F's$ then we get disjoint graphs. Each connected component gives us a Schur function.
\end{Ex}

\begin{significant}
How many connected components do we have?
\end{significant}

If we have length $n$, the question is how many (reverse-)ballot words of length $n$ are there? (Why ballot words?)

\begin{Lem}[Homework]
    For a word $w$ 
    $$E_i(w)=\emptyset\iff w\text{ is Yamanouchi.}$$
\end{Lem}

Assuming this, on length 4 we have the following Yamanouchi words: 
\begin{enumerate}
\begin{multicols}{3}
    \item 1111
    \item 2111
    \item 3211
    \item 3121
    \item 1121
    \item 2211
    \item 1321
    \item 4321
    \item 1211
    \item 2121
\end{multicols}
\end{enumerate}

There are $n\leq x\leq n!$ components. With the lemma comes the following definition:

\begin{Def}
    We say a word $w$ has \term{highest weight} if $E_i(w)=\emptyset$ for all $i$.
\end{Def}

\begin{Th}
    By acting on the reading word we have that $E_i,F_i$ are well defined on skew tableaux (and therefore on tableaux.)
\end{Th}

We can always act on the reading word, but this action doesn't necesarilly guarantee that the result is an SSYT.

\begin{ptcbp}
    Look at the $(i,i+1)$ in a tableau $T$. This will ``look like''
    $$\young(iijj,:::iijjj,::::::ii,::::::::iijj)\footnote{We used this tableau when proving the Schur functions were symmetric.}\footnote{j is i+1, have to change ytableau package.}.$$
    The columns ``cancel''  and some others do to, we can change the left most two $i's$ and the rightmost $i(i+1)$.
\end{ptcbp}

\subsection{Compatibility with Knuth moves and Jeu de Taquin}

\begin{Ex}
    Consider a skew tableau and an inner slide:
    $$\young(1122,::112)\to\young(122,:1112)$$
    But applying $F_1$ means that we get 
    $$\young(1222,::112)\to\young(122,:1122).$$
    \red{DRAW COMMDIAG}
\end{Ex}

Compatibility means commutation at the level of diagrams. 

\section{Day 14| 20230220}

Today we will continue working on the Littlewood-Richardson rule. As a warm-up lets work on an example.

\begin{Ej}
    Compute $E_3$ of the tableau 
    $$\young(5,3346,2234,11111).$$
\end{Ej}

\begin{ptcbr}
    We can focus only on the sub skew tableau
    $$\young(334,::34)$$
    with reading word $33434$, the leftmost un-paired $4$ is the last one so we change the word to $33433$ and then replace on the tableau to get 
    $$\young(5,3346,2233,11111).$$
\end{ptcbr}

Notice we do get a SSYT as we showed last time. We will now work on crystal operators. 

\begin{Th}
    $E_i,F_i$ commute with JDT slides.
\end{Th}
It suffices to check this on $1-2$ tableaux and $E_1,F_1$. This is because $E_i,F_i$ only affect $i,i+1$. (Look at example from last time) This example is the only case that we have to worry about because we can only have at most two rows. The only problematic case is a vertical slide like in the example.\par 
But what about 
$$\young(1222,:::12)\to\young(122,::122),$$
it slides the same way after applying $F_1$:
$$\young(2222,:::12)\to\young(222,::122).$$

\begin{Th}
The operations $E_i,F_i$ preserve the ``being in the same Knuth-equivalence class''. In other words 
$$E_i(w)\sim E_i(v),\quad F_i(w)\sim F_i(v).$$    
\end{Th}

Since rectification is unique and that determines the Knuth-equivalence class, we can use the previous result.

\begin{ptcbr}
    Consider the skew tableau $D_w=\diag(w)$ and $D_v$. Then 
    $$\ins(w)=\ins(v)\To \rect(D_w)=\rect(D_v)$$
    so 
    \begin{align*}
        \rect(E_i(D_w))&=E_i(\rect(D_w))\\
        &=E_i(\rect(D_v))\\
        &=\rect(E_i(D_w))
    \end{align*} 
    Therefore $E_i(D_w)\sim E_i(D_v)$.
\end{ptcbr}

\subsection{Highest Weight}
We will now work with highest-weight elements.

\begin{Lem}
    For a straight shape $\la$, the SSYT's with $\sh(\la)$ all lie in a single connected component of the crystal graph. (i.e. connecting via $E_i,F_i$ we get a connected component.)\par 
    Moreover we get a unique tableau with highest weight ($E_i(T)=\emptyset$). We claim that such a tableau has row $i$ full of $i$'s.
\end{Lem}

Take any shape 
$$\young(~,~~,~~~),$$
as the reading word is Yamanouchi, the first entry is a 1. Then all entries to the left are $1$'s by semi-standardness. The next rightmost element of the next row can't be a 3 by Yamanouchi so it must be a 2 and so on.\par 
But why is everything in the same connected component?\par 
If we have a tableau $T$, then applying $E_i$ we \emph{must} reach $T_\la$. Reversing this process for any $T$ with $F_i$, we get all the tableau. 

\begin{Rmk}
    This method works with no restriction on the letters of the word.
\end{Rmk}

\begin{Cor}
    Every connected component of a crystal of all tableaux of a given skew shape is isomorphic as a directed graph to a straight shape crystal obtained via JDT.
\end{Cor}

With this key step we can compute a Schur function decomposition.

\begin{Ex}
    Let us compute $s_{(3,1)/(1)}$. The crystal of this SSYT is obtained by writing the highest weight fillings of the skew shape:
    $$\young(2,:11),\quad\young(1,:11).$$
    We get the following crystals:
    \begin{center}
        aaaaa
    \end{center}
    By rectifying with JDT we get INSERT DIAGRAMS\par 
    What this means is that adding monomials corresponding to crystal one we get $s_{(2,1)}$ and the other crystal $s_{(3)}$.\par 
    As a shortcut, we draw the Yamanouchi ones, then rectify and that's it.
\end{Ex}

\begin{Cor}
    The coefficient of $s_\nu$ is $s_{\la/\mu}$ is the number of heighest weight SSYT with $\sh(T)=\la/\mu$ that rectify to $\sh(\nu)$. 
    $$\#hw\sh(\la/mu)\word{content}\nu$$
    this is exactly $c^\la_{\mu\nu}$.
\end{Cor}

This completes a proof of the Littlewood-Richardson rule. 
%%%Travis GRIMSHAW SAge crystals in sage 

\subsection{Products of Schur Functions}

There's another Littlewood-Richarson Rule:

\begin{Th}
    Suppose $\mu,\nu$ are straight shapes, then 
    $$s_\mu s_\nu=\sum_{\la}c_{\mu\nu}^\la s_\la.$$
\end{Th}

There's a proof with Knuth-equivalence and concatenation.\par 
We know that $s_\nu\.s_\mu$ can be obtained by finding $s_T$ where $T$ is the skew shape formed by concatenating right down of $\mu$ with LEFT UP$\nu$. Then the product is 
$$\sum_{\la} c_{R\la}^\rho s_\la.$$
To prove it we use Fulton's techniques \cite{FultonYoungTab}.\par 
We want to show $c_{R\la}^{\rho}=c_{\mu\nu}^\la$. This means that the number of Yamanouchi tableaux of shape $\rho/R$ and content $\la$ is the same as $\sh(\la/\mu)$ and content $\nu$. 
\begin{Rmk}
    Consider 
    $$\young(34,223,1124,::::3,::::2222,::::11111).$$
    the lower one has to be $T_\nu$ in any Yamanouchi filling.
\end{Rmk}
We first de-RSK it to get 
$$\young(333,2222,11111)\to \twobyone{123331222111}{111112222333}$$
if $r$ is the first row and $b$ the second one, then we insert $r$ into $U$. But when inserting we are keeping track with $b$, so we label the new squares with $b$ as a skew recording tableau.\par 
Name $Q$ such tableau, we claim that $Q$ is a ballot SSYT shape $\la/\mu$ content $\nu$.\par 
Putting this together in the example we get 
$$U=\young(34,223,1124)\leftarrow 123331222111$$
\red{READ IN FULTON AND UNDERSTAND BIJECTion}

\chapter{Representation Theory: A Crash Course}

\section{Day 15| 20230222}


Representation is a big and not unified area, so we will talk only about what we need for combinatorics.

\begin{Def}
    A group is a set $(G,\ast)$ such that $\ast$ is a binary operation which is associative, possesses an identity element and every element possesses an inverse.\par 
    We say a matrix representation of a group is an assignment $g\mapsto M_g\in\GL_n(\bC)$ for $g\in G$ with $M_gM_h=M_{g\ast h}$.\par 
    If the assignment is injective we say the representation is faithful.
\end{Def}

\begin{Ex}
    Some groups that we will use are $(S_n,\circ)$, the general linear group $(\GL_n(\bC),\.)$, the Multiplicative subgroup of the real numbers $(\bR\less\set{0},\.)$.\par 
    On the other hand group representations of $S_3$ we have that the composition is the operation. We can trivially represent it as $\sg\mapsto (1)$ for every $\sg\in S_3$. This representation is not faithful.\par 
    We also have the \emph{sign representation} 
    \begin{itemize}\begin{multicols}{3}
        \itemsep=-0.4em
\item $\id\mapsto (1)$.     
\item $(12)\mapsto (-1)$.       
\item $(13)\mapsto (-1)$.       
\item $(23)\mapsto (-1)$.       
\item $(123)\mapsto (1)$.       
\item $(132)\mapsto (1)$.        
    \end{multicols}
    \end{itemize}
    These are the only 1-dimensional representations of $S_3$. In fact for $S_n$ this is true, there are only 2 one-dimensional representation.\par 
    We can represent our permutations as permutation matrices!
    \begin{itemize}\begin{multicols}{3}
        \itemsep=-0.4em
\item $\id\mapsto \threebythree{1}{0}{0}{0}{1}{0}{0}{0}{1}$.     
\item $(12)\mapsto \threebythree{0}{1}{0}{1}{0}{0}{0}{0}{1}$.       
\item $(13)\mapsto \threebythree{0}{0}{1}{0}{1}{0}{1}{0}{0}$.       
\item $(23)\mapsto \threebythree{1}{0}{0}{0}{0}{1}{0}{1}{0}$.        
\item $(123)\mapsto\threebythree{0}{0}{1}{1}{0}{0}{0}{1}{0}$.       
\item $(132)\mapsto \threebythree{0}{1}{0}{0}{0}{1}{1}{0}{0}$.        
    \end{multicols}
    \end{itemize}
    In general $\sg\mapsto M_\sg$ where $(M_\sg)_{i,j}=\dl_{i,\pi(j)}$. This representation is faithful, but it's \emph{too big}.
\end{Ex}

We can notice that $v=\threebyone{1}{1}{1}$ is an eigenvector with eigenvalue 1 of all of these matrices. The eigenspace $\gen(v)$ is fixed by all of these matrices. The orthogonal complement to $\gen(v)$ is rotated about the normal axis when acted by this matrices, such plane is 
$$\gen\left(\threebyone{1}{-1}{0},\threebyone{0}{1}{-1}\right).$$
If we add our eigenvector to the basis then 
$$\bonj{\id}_\cB^\cC=\threebythree{1}{1}{0}{1}{-1}{1}{1}{0}{-1}\To\bonj{\id}^\cB_\cC=\frac{1}{3}\threebythree{1}{1}{1}{2}{-1}{-1}{1}{1}{-2}.$$

\begin{Lem}
    If $g\mapsto M_g$ is a representation, then $g\mapsto A^{-1}M_gA$ is also a representation.
\end{Lem}

\begin{ptcbp}
    $A^{-1}M_gAA^{-1}M_hA=A^{-1}M_{g\ast h}A$. 
\end{ptcbp}

Conjugating with our matrix we get the following representation:
\begin{itemize}\begin{multicols}{3}
    \itemsep=-0.4em
\item $\id\mapsto \threebythree{1}{0}{0}{0}{1}{0}{0}{0}{1}$.     
\item $(12)\mapsto \threebythree{1}{0}{0}{0}{-1}{1}{0}{0}{1}$.       
\item $(13)\mapsto \threebythree{1}{0}{0}{0}{0}{-1}{0}{-1}{0}$.              
\end{multicols}
\end{itemize}

The fourth representation of $S_3$ comes from the two-by-two components of the block diagonal matrices in question. Knowing where the generators go is sufficient to know where every element maps. This means that 
\begin{align*}
    &(132)=(12)(13)\mapsto\twobytwo{-1}{1}{-1}{0}.\\
    &(123)=(13)(12)\mapsto\twobytwo{0}{-1}{1}{-1}.\\
    &(23)=(13)(132)\mapsto\twobytwo{1}{0}{1}{-1}.
\end{align*}
But how would we have found this representation without recurring to the basis? We can think of our representation as we did, every group element is a matrix.\par 
Another way is a homomorphism $G\to\GL_n(\bC)$. Also we can consider it as a vector space space action 
$$G\.V\: G\x V\to V.$$
With this understanding $3$ and $3'$ aren't fundamentally different.

\begin{Def}
Two representations $g\mapsto M_g$ and $g\mapsto N_g$ are isomorphic whenever there exists $A\in\GL_n(\bC)$ such that $A^{-1}M_gA=N_g$.\par 
In terms of the vector spaces, two representations $V,W$ are isomorphic if there's an isomorphism that preserves the group action. 
\end{Def}

\begin{itemize}
    \itemsep=-0.4em
    \item Can we have isomorphic representations between dimensions? No, but,
    \item can we have non-isomorphic representations of the same dimension? Yes! The one dimensional ones aren't isomorphic.
\end{itemize}
\subsection{Operations on representations}

The direct sum acts on vector spaces as $V\oplus W$ or on maps as 
$$(g\mapsto M_g)\oplus(g\mapsto N_g)=g\mapsto\twobytwo{M_g}{}{}{N_g}.$$

\begin{Ex}
    The permutation representation for $S_3$ is the direct sum of the standard one and the trivial one.
\end{Ex}

\begin{Def}
    A representation is \term{irreducible}\footnote{indecomposable means the same as irreducible when working over $\bC$.} if it is not the direct sum of smaller dimensional representation.
\end{Def}
Any number is a unique product of primes, so in an analogous way, any representation is a direct sum of irreducibles.

\begin{Th}[Maschke/Schur]
    Every complex representation of a finite group $G$ is uniquely (up to isomorphism) a direct sum of irreducibles.
\end{Th}

We will see that irreducible representations of the symmetric group correspond to Schur functions. 

\section{Day 16| 20230224}

The main goal of a representation is to break it down into irreducible representations. We want to classify into irreducible representations.

\begin{Prop}
    The number of irreducible representations of a finite group $G$ is the number of conjugacy classes.
\end{Prop}

Recall $g,h\in G$ are conjugate if $h=kgk^{-1}$ for some $k\in G$. 

\begin{Ex}
    If $G$ is abelian, the conjugacy classes are singletons. This means that the number of irreducible representations of $G$ is $|G|$. As we represent over complex numbers, we map each element of $G$ to a $|G|^{\text{th}}$ root of unity.
\end{Ex}

\begin{Ex}
    Recall that conjugacy classes in the symmetric group are determined by cycle type. Notice that the number of conjugacy classes is $5=p(4)$. 
    \begin{table*}[h]
        \centering
        %\arraystretch{1.3}
        \begin{tabular}{rrrr}\toprule
            Partition & Cycle type & Elements of conjugacy class\\ \midrule
            $(1,1,1,1)$& 4 1-cycles & $()$ (identity element)\\
            $(2,1,1)$& 1 transposition & $(12),(13),(14),$\\
            &&$(23),(24),(34)$\\
            $(2,2)$ & 2 transpositions & $(12)(34),(13)(24),(14)(23)$\\
            $(3,1)$ & 1 3-cycle& $(123),(132),(234),(243),$\\
            &&$(341),(314),(412),(421)$\\
            $(4)$ & 1 4-cycle & $(1234),(1243),(1324),$\\
            &&$(1342),(1423),(1432)$\\
       \bottomrule
        \end{tabular}
        \legend{Symmetric Group $S_4$ cycle structure}
        \end{table*}
\end{Ex}

We now have $2$ irreducible representations, the trivial and sign one. The rest we will find with tableaux.
\begin{Prop}
    There is one irreducible representation $V_\la$ of $S_n$ for each partition $\la\vdash n$.
\end{Prop}

\subsection{Specht's construction of $V_\la$}

Sometimes this $V_\la$'s are called Specht modules, this means irreducible representation of $S_n$. First remember that $S_n$ acts on $\bC[x_1,x_2,\dots,x_n]$.\par 
We can think of $(\bC[x_1,\dots,x_n],+)$ as an infinite dimensional $S_n$ representation. This in the sense that 
$$\bC[x_1,x_2,\dots,x_n]=\bigoplus_{d=0}^\infty\set{\text{degree d homogenous component}}$$
We will construct $V_\la$ as a sub-representation of $\bC[x_1,\dots,x_n]$.

\begin{Def}
    Let $T$ be a standard filling (1 to n no restrictions on order) of a shape $\la$. The \term{Garnir polynomial} is 
    $$F_T=\prod_{(\ast)}(x_j-x_i)$$
    where we sum through $i$ ``below'' $j$ in the same column of $T$.
\end{Def}

\begin{Ex}
    Consider the partition $(2,2,1)$ and a filling
    $$\young(4,13,52)$$
    so we look at the first column. We begin by adding factors 
    $$(x_4-x_1)(x_4-x_5)(x_1-x_5)$$
    and in the second column, only get $(x_3-x_2)$. So $F_T$ is the product
    $$F_{T}=(x_4-x_1)(x_4-x_5)(x_1-x_5)(x_3-x_2).$$
\end{Ex}

\begin{Def}
    The Specht module is $V_\la=\gen\set{F_T\:\ T\text{ is a standard filling of }\la}$.
\end{Def}

\begin{Lem}\label{lem-action-of-Sn-on-Vlambda}
    $S_n$ acts on $V_\la$ by permuting variables.
\end{Lem}

\begin{Ex}
    In the previous example, $(12)$ acts on $F_T$ as 
    $$(12)\.F_T=(x_4-x_2)(x_4-x_5)(x_2-x_5)(x_3-x_1)$$
    so $(12)T$ is 
    $$\young(4,23,51).$$
\end{Ex}

The proof of the lemma \ref{lem-action-of-Sn-on-Vlambda} begins by determining the action of $\pi\in S_n$ over the basis. We can see that $\pi F_T=F_{(\pi T)}$ and after that and we extend linearly to all elements, since the action on the generators determines the action on the whole space.

\begin{Prop}
    The set of $F_T$'s such that $T$ is a SYT is a basis for $V_\la$. In particular 
    $$\dim(V_\la)=\# SYT(\la)$$
    where we can use the hook-length formula. 
\end{Prop}

We will see the proof next class, for now, an example:

\begin{Ex}
    Consider $V_{(2,1)}$, we have the following possible fillings of $\sh(2,1)$:
    $$\young(3,12),\quad\young(2,13),\quad\young(1,23),\quad\young(3,21),\quad\young(2,31),\quad\young(1,32).$$
    By taking the Garnir polynomial of each filling $T$ we can find the generators for our $V_{(2,1)}$:
    $$V_{(2,1)}=\gen(x_3-x_1,x_2-x_1,x_1-x_2,x_3-x_2,x_2-x_3,x_1-x_3)$$
    Clearly we don't need some of them due to signs. After eliminating the negatives, we can see that 
    $$x_3-x_2=(x_3-x_1)-(x_2-x_1)$$
    so that we may eliminate it as well. We are only left with $x_3-x_1$ and $x_2-x_1$, the ones that correspond to SYT and we see that the dimension of $V_{(2,1)}$ is indeed 2, the number of SYT's of shape $(2,1)$.
\end{Ex}

\begin{Ej}
    Compute $V_{(1,1,1)}$ and $V_{(3)}$. What is their dimension? \hint{We saw both of this represntations on last class.}
\end{Ej}

\begin{ptcbr}
    Both representations have dimension $1$ as there's only one SYT of shape $(1,1,1)$ and $(3)$:
    $$\young(3,2,1),\word{and}\young(123).$$ 
    For $V_{(3)}$ this is the span of $1$, because we can't make any Garnir polynomials. Also $S_3$ acts on trivially on $1$. This means $V_{(3)}$ that is the trivial representation.\par 
    For $V_{(1,1,1)}$ we have that it's generated by $(x_2-x_1)(x_3-x_1)(x_3-x_2)$. We can see that this is the sign representation.
\end{ptcbr}

Let's now see why the representation $V_{(2,1)}$ is the same as the standard representation we found last time.\par 
First, $V_{(2,1)}$ is a subspace of $\bC[x,y,z]_{(1)}$, the homogenous linear polynomials of degree 1 and we have
$$\bC[x,y,z]_{(1)}=\gen(x,y,z).$$
As $V_{(2,1)}=\gen(z-x,y-x)=\gen\left(\threebyone{-1}{0}{1},\threebyone{-1}{1}{0},\right)$. This is the action of $S_3$ on the orthogonal subspace $\threebyone{1}{1}{1}^\sT$.

\begin{Lem}
    The permutation representation of $S_n$ is 
    $$V_{(n)}\oplus V_{(n-1,1)}.$$
\end{Lem}

On monday we will continue with tensor products and $V_\la\to s_\la$, $V\la\ox V_\mu\to s_\la s_mu$

\section{Day 17| 20230227}

Going back to Yamanouchi words on 2 letters, the way to solve it is to consider the crystals. Each connected component contains a sequence with three 2's and two 1's which can be counted using $\binom{n}{\floor{n/2}}$ as this question is equivalent to asking number of words of length $2n+1$ with $n+1$ ones and $n$ twos.

\subsection{Garnir polynomials}

Recall that $T$ is a filling on $\la$ with $[n]$ with no restrictions on rows or columns. $T$'s Garnir polynomial is $\prod(x_i-x_j)$ where $i$ is ``above'' $j$. From this, $V_\la$ is $S_n$-invariant. This means that $\pi v\in V_\la$ when $v\in V_\la$ and $\pi\in S_n$.\par 
We now need a \emph{straightening algorithm} to convert $F_T$'s to other $F_T$'s.

\begin{Lem}[Column straightening]
    If $T$ is a filling of $\la$ with $[n]$ and $T'$ is formed from $T$ by ordering columns, then $F_{T'}=(\pm)F_T$.
\end{Lem}

\begin{Ex}
    Consider the fillings $T$ and $T'$ respectively: 
    $$\young(87,125,4936)\quad\to\quad\young(89,475,1236).$$
    We have
    $$
    \left\lbrace
    \begin{aligned}
        &F_T=(x_8-x_1)\dots\\
        &F_{T'}=(x_8-x_1)\dots\\
    \end{aligned}
    \right.
    $$
\end{Ex}

Proof was omitted in class \red{LOOK AT MARIA NOTES}

\begin{Lem}[Row straightening]
    Suppose $T$ is column-increasing and we do the following:
    \begin{enumerate}[i)]
        \itemsep=-0.4em
        \item Choose the topmost row having a decrease (if it's not row increasing).
        \item Choose the rightmost decrease in that row.
        \item Define the \term{Garnir operator}
        $$g_{A,B}=\sum_{(\ast)}\sgn(\sg)\sg$$
        where the sum is taken over $\sg\in S_{A\cup B}$ which preserve column increases.\par 
        Then 
        $$g_{A,B}F_T=0\iff \sum_\sg\sgn(\sg)F_{\sg(T)}=0.$$
    \end{enumerate}
\end{Lem}

\begin{Ex}
    In the filling  
    $$\young(89,475,1236)$$
    we have $A$ to be the column above and including the $7$, while $B$ is the column including and below $5$. Then the Garnir operator is 
    $$g_{A,B}=\id-(57)+(37)(59)+(735)+(597)-(3597).$$
    The result of applying each term of the operator to the filling results in 
    $$\young(89,457,1236),\quad\young(85,439,1276),quad\young(89,437,1256),\quad\young(87,459,1236),\quad\young(87,439,1256).$$
    and notice that (properrty is now there, which one column inc or row incr?) so that 
    $$F_T=F_1-F_2-F_3-F_4+F_5$$
\end{Ex}

\begin{Prop}
    Irreducibility of $V_\la$
\end{Prop}

\subsection{Tensor product on representations}

The \emph{inner} tensor product is defined on all representations whereas the \emph{outer} tensor product is specific to the $S_n$ case. 

\begin{Prop}
    If $V,W$ are vector spaces of dimension $n$ and $m$, then $\dim(V\ox W)=mn$.   
\end{Prop}

The construction of the tensor product that we will use is the one of the free vector space over $V\x W$ modulo the relations of bilinearity.

\begin{Prop}
    If $V,W$ are $S_n$-representations, then $V\ox W$ is an $S_n$ representation as well given by 
    $$\pi(v\ox w)=(M_\pi v\ox M_\pi w).$$
\end{Prop}

The \term{Kronecker problem} is that we have $V_\la$ and $V_\mu$ and we would like to determine the decomposition of $V_\la\ox V_\mu$ into irreducibles.

\section{Day 18| 20230301}

The inner tensor product is 

$$g(v\ox w)=M_gv\ox N_gw$$

so if $V,W$ represent, $V\ox W$ represents. For matrices $A\ox B$ is a block matrix.

\subsection{Outer Tensor Product}

\begin{Def}
    Suppose $H\leq G$ for a group $G$ and $V$ represents $H$. Then the induced representation of $G$ is 
    $$\bC G\ox_{\bC H}V.$$ 
    A basis is the basis of $V$ tensored by coset elements.
\end{Def}

\begin{Ex}
    Consider the trivial representation of $S_2$, let us call it $1_{S_2}$. Let us now induce from $S_2$ to $S_3$, we are fixing the $3$ so $S_2=\gen((12))$. Thus we may find a basis 
    $$v_1=123\ox v_0,\quad v_2=132\ox v_0,\quad v_3=312\ox v_0,$$
    where $v_0$ is the only basis element of $1_{S_2}$. Sending this to matrices we get the permutation representation.
\end{Ex}

\begin{Def}
    If $V$ repreesents $G$ and $H\leq G$, then restricting the representation to $H$ means just taking the \emph{ones in $H$}.
\end{Def}

With the induced and restriced representations we can now go on to defining the outer tensor product of representations.

\begin{Def}
    The \term{outer tensor product} of $V,W$ representations of $S_n$ and $S_m$ is 
    $$Ind_{S_n\x S_m}^{S_{n+m}}V\ox W.$$ 
\end{Def}

Notice that $V\ox W$ is a representation of $S_n\x S_m$ so we induce it to the larger group $S_{n+m}$. Notice that we may interpret a permutation in $S_n\x S_m$ as a permutation of the word 

The difference is that $V,W$ in the inner one are in the same group. Now we get an $S_{n+m}$ representation from the outer.  The \term{Kronecker problem} looks for irreducible representations of $V_\la\ox_{in}V_{\mu}=\bigoplus g){\la\mu}^\nu V_\nu$.\par 
However it is possible to find the decomposition of the outer tensor product:
$$V_\mu\ox_{out}V_\nu=\bigoplus_\la c_{\mu\nu}^{\la}V_\la$$
where $c_{\mu\nu}^\la$ is the Littlewood-Richardson coefficient. This is analogous to the product of two Schur functions
$$s_\mu s_\la=\sum_\la c_{\mu\nu}^\la s_\la.$$
\begin{Ex}
    Consider $V_{(2)}\ox_{out}V_{(1)}$, this the trivial representation of $S_2\x S_1$ which means this is the induction from $S_2\x S_1$ to $S_3$.\par 
    Notice that the group $S_2\x S_1\isom S_2$, so from before, we found that this was the permutation representation of $S_3$. We have decomposed this (REF WHERE) as 
    $$V_{(2,1)}\oplus V_{(3)}.$$
    This is analogous to $s_{(2)}s_{(1)}$.
\end{Ex}
\red{Also read example in notes column sign, row trivial} We wish to understand the previous correspondence. 

\begin{Def}
    The \term{Frobenius map} takes a representation $V=\bigoplus c_\la V_\la$ to $\sum c_\la s_\la$. In other words, takes irreducibles $V_\la$ to basis elements $s_\la$ and extend by linearity.
\end{Def}

Notice that 
$$\text{Frob}(V_\la\ox_oV_\mu)=s_\la s_mu\To \text{Frob}(V\ox_oW)=Frob(V)Frob(w).$$
We may extend to virtual representations which are complex formal sums of representations. Then $Frob\: (Virt,\oplus,\ox)\to\La$ is a ring homomorphism.\par 
But what's the deal with Schur positivity, this theory gives us a corollary.

\begin{Cor}
    A homogenous degree $d$ symmetric function is a Frobenius character of some representation if and only if $f$ is Schur positive.
\end{Cor}

This means that there are two strategies when working in combinatorial represetation theory.
\begin{enumerate}
    \item We have a representation for which we can decompose $Frob(V)$ indto Schur functions, then we can find a decomposition of $V$ into irreducibles.
    \item If we have a collection of symmetric functions which seem to be Schur positive, then we can show that the fact is true by finding a representation $V_i$ such that $f_i=Frob(V_i)$.
\end{enumerate}

\section{Day 19| 20230303}

\begin{Ej}
    Write $s_{(2,1)}$ in terms of $p_\la$ and $p_{(2,1)}$ in terms of $s_\la$.
\end{Ej}

Recall that we have some formulas to go between basis of symmetric functions. The full is available in \href{http://www.mathematicalgemstones.com/gemstones/diamond/summary-symmetric-functions-transition-table/}{Maria's webpage}. With what we know, we can't solve the previous exercise.

\subsection{Murnaghan-Nakayama Rule}

\begin{Def}
    The \term{character} $\chi_V$ of a representation $V$ of a group $G$ is 
    $$\chi_V\: G\to\bC,\ g\mapsto \tr(M_g)=\sum(\text{diagonal elements})=\sum(\text{eigenvalues}).$$
\end{Def}
No matter what basis we choose, the character is invariant.

\begin{Lem}
        \item $\chi_V$ is constant on conjugacy classes.
\end{Lem}

\begin{ptcbp}
$\chi_V(hgh^{-1})=\tr(M_{hgh^{-1}})=\tr(M_hM_gM_{h}^{-1})=\tr(M_g)=\chi_V(g)$.
\end{ptcbp}

From this we can think of the character as a function from the conjugacy classes. As the amount of irreducible representations is the number of conjugacy classes, then we can write a character table
\begin{center}
    TABLE
\end{center}
Characters are also additive across representations, this means that 
$$\chi_{V\oplus W}=\chi_V+\chi_W.$$
So knowing irreducibles allows us to find characters for all other representations. The other direction is much more important, if we know $\chi_V$, we can uniquely decompose it as a linear combination of irreducible characters. So we can deduce the decomposition of $V$ into irreducible representations.

\begin{Ex}
    We will find the character table of $S_2$. As $S_2$ is abelian, every element is in its own conjugacy class:
    \begin{table*}[h]
        \centering
        %\arraystretch{1.3}
        \begin{tabular}{rrrr}\toprule
            $S_2$ &$\id$& $(2)$\\ \midrule
            $\chi_{(2)}$&1 & 1\\
            $\chi_{(1,1)}$&1 & -1\\
       \bottomrule
        \end{tabular}
        \legend{Character table for $S_2$}
        \end{table*}
\end{Ex}


\begin{Ex}
    We will find the character table of $S_3$:
    \begin{table*}[h]
        \centering
        %\arraystretch{1.3}
        \begin{tabular}{rrrr}\toprule
            $S_3$ &$\id$& $(12)$&$(123)$\\ \midrule
            $\chi_{(3)}$&1 & 1&1\\
            $\chi_{(1,1,1)}$&1 & -1&1\\
            $\chi_{(2,1)}$&2 & 0&-1\\
       \bottomrule
        \end{tabular}
        \legend{Character table for $S_3$}
        \end{table*}
\end{Ex}

The character table for $\chi_{\text{reg}S_3}$ is $(600)$ so we may decompose the character as 
$$2(20-1)+(111)+(1-11)\To V_{\text{reg}}=\text{triv}\oplus\text{sign}\oplus\text{std}^2.$$
The regular represntation always decomposes a $dim*character$. This is an application of RSK as well \red{AUDIO 20min}

We will alternatively define the Frobenius map with characters.
\begin{Def}
    Suppose $V$ represents $S_n$, then 
    $$\Frob(V)=\frac{1}{n!}\sum_{\pi\in S_n}\chi_V(\pi)p_{c(\pi)}$$
    where $c((12)(35)(467))=(3,2,2)$.
\end{Def}

This is summing over $n!$ elements, but remember some of them share cycle type. 

\begin{Lem}
    Under this definition, this can also be written as 
    $$\Frob(V)=\sum_{\la\vdash n}\chi_V(\pi\in\la\text{conj.class})\frac{p_\la}{z_\la}$$
    where $z_\la=\prod k^{m_k}m_k!$.
\end{Lem}

\begin{ptcbp}
    We have that the size of the conjugacy class of cycle type $\la$ is $n!/z_\la$. So rewrtiting the Frobenius map we get 
    $$\Frob=\frac{1}{n!}\sum_{\pi\in S_n}\chi_V(\pi)p_{c(\pi)}=\frac{1}{n!}\sum_{\la\vdash n}\sum_{\pi\text{cyc.type}\la}\chi_V(\pi)p_{\la}$$
    Since character is constant, we have 
    $$\frac{1}{n!}\sum_{\la\vdash n}(\#\text{conj.class cyctype}\la)\chi_V(\pi_\la)p_\la$$
    that amount is $n!/z_\la$ so factorials cancel out and we get the desired formula.
\end{ptcbp}

\begin{Ex}
    Recall that the character table for $\chi_{(2,1)}$ is $(2,0,-1)$ so
    $$\Frob(V_{(2,1)})=2\frac{p_{(1,1,1)}}{z_{(1,1,1)}}+0p_{(2,1)}/z-\frac{p_3}{z_3}=\frac{1}{3}p_1^3-\frac{1}{3}p_3=m_{(2,1)}+2m_{(1,1,1)}=s_{(2,1)}.$$
    Now for instance from the trivial character, $\Frob(V_{(3)})$, the character table is $(1,-1,1)$ and 
\end{Ex}

In essence the coefficients are the character tables.

\begin{Th}
    The character tables for $S_n$ are the transition matrices from $(s_\la)$ to the normalized power sum: $(p_\la/z_\la)$. 
\end{Th}

The product for this fact can be found in \cite{StanleyEnum2}. This theorem is also equivalent to the fact that both Frobenius maps are equivalent.\par 
We now ask, 
\begin{significant}
    Is there a combinatorial way to compute $\chi_\mu(\la)$?
\end{significant}

To derive it, we will use a duality. The Schur and power sum bases are self dual with respect to the Hall inner product so 
$$\chi_\mu(\la)=\text{coeff.}\frac{p_\la}{z_\la}\word{in} s_\mu=\braket{s_\mu}{p_\la}=\text{coeff.}s_\mu\word{in}p_\la.$$
So $p_\la=\sum_\mu\chi_{\mu}(\la)s_{\mu}.$

\section{Day 20| 20230306}

\subsection*{The Inverse Murnaghan-Nakayama Rule}

We wish to compute $\chi_U(\la)$, the character of $V_\mu$ on a permutation $\pi$ of cycle type $\la$. This is the coefficient $\braket{s_\mu}{p_\la}$, the coefficient of $s_\mu$ in $p_\la$.

\begin{Def}
    A \term{border strip} or a ribbon is a connected skew-shape containing no $2\x 2$ square.
\end{Def}

\begin{Ex}
    The tableau
    $$\young(~~~~~,::::~~~~~,:::::::::~,:::::::::~,:::::::::~~~)$$
    is a ribbon, the tableau
    $$\young(~~~,:::~~~,::::::~,::::::~,::::::~~)$$
    is not a ribbon because it's not connected. Finally the tableau 
    $$\young(~~~~~,:::~~,::::~~~~)$$
    has a $2\x 2$ square.
\end{Ex}

\begin{Def}
    The height of a border strip $\la/\mu$ is $\#$rows$-1$.\par
    A \term{border strip tableau} with shape $\la$ is a filling with positive integers such that 
    \begin{itemize}
        \item row and columns are weakly increasing 
        \item Every integer forms a border strip.
    \end{itemize}
\end{Def}

\begin{Ex}
    The tableau 
    $$\young(3355,1245,12222,11112)$$
    is a border strip tableau
\end{Ex}

\begin{Th}
    The character 
    $$\chi_\mu(\la)=\braket{s_\mu}{p_\la}=\sum_{(\ast)}\prod_{i=1}^{\ell(\la)}(-1)^{\operatorname{ht}(\text{strip}(i))}$$
    where the sum runs through border strip tableaux $T$ with shape $\mu$ and content $\la$.
\end{Th}

\begin{Ex}
    Let us find $\braket{s_{\sh(3,2,1)}}{p_{(3,3)}}$. We wish to fill border strip tableau with $111222$. We have the following fillings 
    $$\young(2,22,111),\word{and}\young(1,12,122).$$
    Calculating the heights we have 
    $$(-1)^0(-1)^1=-1,\word{and}(-1)^2(-1)^2=-1$$
    so $\braket{s_{\sh(3,2,1)}}{p_{(3,3)}}=-1-1=-2$.
The coefficients might not be positive but at least they are integers. 
\end{Ex}

\begin{Ej}
Calculate $\braket{s_{\sh(2,1)}}{p_{(2,1)}}$.
\end{Ej}

\begin{ptcb}
    The tableaux are 
    $$\young(2,11),\word{and}\young(1,12)$$
    so we get $1-1=0$.
\end{ptcb}

\begin{Ex}
    Notice that $\braket{s_{\sh(3,2)}}{p_{(1,1,1,1,1)}}$ is the number of standard Young tableaux because we are filling with $12345$.\par 
    On the other hand 
    $$\braket{s_{\sh(\mu)}}{p_{(n)}}$$
    is either $0$ if $\mu$ is not a \emph{hook} and $(-1)^{\l(\mu)-1}$ when it actually is a hook.
\end{Ex}
The following proof comes from Egge's symmetric function, we will separate it into stages.

\begin{Lem}
    $p_r=\sum_{j=0}^{r-1}(-1)^js_{(r-j,1,1,\dots,1)}$ where there are $k$ ones.
\end{Lem}

\begin{ptcbp}
    We have that 
    $$s_{hook}=\sum_{(\ast)}x^T$$
    we wish to cancel $x^T$'s as follows  
$$\young(y,~,~,~~~~x),\word{with}\young(x,y,~,~,~~~~)$$
if $x>y$. Else if $x\leq y$ we pair with 
$$\young(~,~,~~~~xy).$$
This is a sign-reversing involution and the only edge cases are 
$$\young(y~~~~x),\word{and}\young(y,~,~,~,x)$$
so the fixed points are tableau of the form
$$\young(ii~~~i)$$
which contribute monomials of the form $x_i^r$. So monomials that don't cancel out are the power sum symmetric functions.
\end{ptcbp}
Let's see an example

\begin{Ex}
What about $p_4$?    
\end{Ex}

\begin{Lem}
    We have
    $$s_\mu p_r=\sum_{(\ast)}(-1)^{\text{ht}(\la/\mu)}s_\la$$
    where the sum runs through $\la$ such that $\la/\mu$ is a border strip of size $r$.
\end{Lem}

Recall the Pieri rules which say 
$$s_\mu h_r=\sum_{(\ast)}s_\la$$
where the sum is through $\la$ such that $\la/\mu$ is a horizontal strip of size $r$. The $e$ Pieri rule instead goes
$$s_\mu e_r=\sum_{(\ast)}s_\la$$
where the sum now is through vertical strips of size $r$.\par 
The tableaux 
$$\young(~\.,~\.,~~~\.,~~~~\.),\word{and}\young(~,~xx,~~~,~~~~,xxx)$$
represent the veritcal and horizonal strips. But the tableau
$$\young(~x,~xxx,~~~x,~~~~)$$
represents the border strip.

\begin{ptcbp}
    First notice that 
    $$s_{(r-j,1,1,\dots,1)}=\sum_{k=0}^{j}(-1)^{j-k}h_{r-k}e_k.$$
    The idea is that hook shapes are similar to vertical and horizontal strips.
\end{ptcbp}

\begin{Ex}
    Consider $s_{\sh(3,1,1)}$. By the formula this should be 
    $$h_{\sh(5)}e_0-h_4e_1+h_3e_2$$
     and we stop here because the height here is $j=2$. This is the same as 
    $$s_{\sh(5)}e_0-s_4e_1+s_3e_2.$$
    By the Pieri rule this is  
    $$s_{\sh(5)}-(s_{\sh(5)}+s_{\sh(4,1)})+(s_{\sh(4,1)}+s_{\sh(3,1,1)}).$$
    So all terms cancel except for $s_{(r-j,1,1,\dots,1)}$.
\end{Ex}

Substituting this result in the lemma

$$s_\mu p_r=\sum_{j=0}^{r-1}(-1)^js_\mu\sum_{k=0}^{j}(-1)^{k-j}h_{r-k}e_k.$$
The $(-1)$ gets a $k$ power and we are left with 
$$\sum_{j=0}^{r-1}\sum_{k=0}^{j}(-1)^ks_\mu h_{r-k}e_k$$
Where $h$ adds horzontal strips and $e$ adds vertical strips. And they are gonna cancel unless they are a border strip. 
$$\young(rrb,~~b,~~~~,~~~~rb,~~~~~~r)$$
So the difference is that looking at the shape, this contributes $s_\la$. We can \emph{toggle something} so it does change the height. 

\chapter{Counting with Group Actions}
\section{Day 21| 20230308}

\begin{Def}
    An \term{action} of a group $G$ on a set $X$ is a map 
    $$G\x X\to X,\ (g,x)\mapsto g\.x$$
    such that $h\.(g\. x)=(hg)\.x$ and $\id\. x=x$.
\end{Def}

We have already seen group actions when $X$ is a vector space. Representations are actions: $M_g\in\End(V)$. This map is bijective because we can find an inverse to the action.

\begin{Ex}
    A group action which is not a representation is $S_n$ acting on $[n]$ by $\pi\. i=\pi(i)$. This is an action because composition does what we want it to do.\par 
    Also $S_n$ acts on itself:
    \vspace*{-0.4em}
    \begin{itemize}
        \itemsep=-0.4em
        \item By conjugation: $\pi.\sg=\pi\sg\pi^{-1}$.
        \item By left-multiplication: $\pi.\sg=\pi\sg$.
    \end{itemize}
\end{Ex}

Every group acts on itself by multiplication. 

\begin{Def}
    An action $G\. X$ is transitive if $g\.x=y$ for some $g\in G$ and all $x,y\in X$.
\end{Def}

On the previous examples, $S_n\.\bonj{n}$ is transitive. Left multiplication is transitive, but conjugation is not.

\begin{Ex}
    The group $\quot{\bZ}{5\bZ}$ can be thought of $\genr{(12345)}\leq S_5$. This acts on the set of points of a 5-pointed star by rotation.
\end{Ex}

We wish to study the orbits of the actions which tell us how \emph{not-transitive} an action is.

\begin{Def}
    The \term{orbit} of a point $x\in X$ under an action $G\.X$ is 
    $$\Orb(x)=\set{g\.x\:\ g\in G}.$$
\end{Def}

The idea is that when we have a cyclic group, these sets look like \emph{orbits around the center}. Also, be quick to notice that 
$$\Orb(x)=\Orb(g\. x),\quad g\in G$$
which means that the orbits partition the set $X$. In particular, ``being in the same orbit'' is an equivalence relation.\par 
In the previous examples:
\vspace*{-0.4em}
    \begin{itemize}
        \itemsep=-0.4em
        \item Conjugations's orbits are the conjugacy classes.
        \item Left multiplication's orbit is only one. 
    \end{itemize}

\begin{Ex}
    For the action $(S_3\x S_2)\.\bonj{5}$, we have orbits $[3]$ and $\set{4,5}$.
\end{Ex}

Our objective now is to count orbits. This count is related to stabilizers. 

\begin{Def}
    The \term{stabilizer} of $x\in X$ under $G\.X$ is 
    $$\Stab(x)=\set{g\in G\:\ g\.x=x}.$$
\end{Def}

\begin{Ex}
    In $S_n\.\bonj{n}$ we have
    $$\Stab_{S_n}(n)=S_{n-1}$$
    because we can freely move the other $n-1$ elements. Now consider the conjugation action on $S_5$, then 
    $$\Stab_{S_5}((123)(45))=C_3\x C_2.$$
\end{Ex}

Now how do the orbit and stabilizer relate? The main reference is \cite{Sagan} in chapter 6.

\begin{Th}[Orbit-Stabilizer Theorem]
    For $G\.X$ a group action, and a point $x\in X$ we have 
    $$|\Stab(x)||\Orb(x)|=|G|.$$
\end{Th}

\begin{ptcbp}
    If $s$ is the size of the stabilizer, then we consider $y\in\Orb(x)$. This means that $y=g\.x$, so we get $s$ elements which send $x$ to $y$. In other words 
    $$h\.x=g\.x\To (g^{-1}h)\.x=x$$
    so $g^{-1}h\in\Stab(x)$, i.e. $h=g\.r$ for some $r\in\Stab(x)$.\par 
    So there exists $s$ elements of $G$ sending $x$ to $y$ for $y\in\Orb(x)$.
\end{ptcbp}

\begin{Ex}
    We will find the size of a conjugacy class of cycle type $\la$. We can identify this as the orbit of the conjugacy action. This is, by Orbit-Stabilizer:
    $$\frac{|S_n|}{|\Stab(\pi_\la)|}.$$
    For example if $\la=(3,3,2,1,1)$ then $\pi_\la=(123)(456)(78)(9)(10)$. To stabilize this we can still do cyclic group actions on the cycles. This accounts for $C_3\x C_3\x C_2$. We add two $2!$ reswitching. If $m_i$ is the number of $i$'s in $\la$, then $m_1=2$, $m_2=1$ and $m_3=2$. So we have:
    $$\frac{|S_n|}{|\Stab(\pi_\la)|}=\frac{n!}{\prod_{i}i^{m_i}m_i!}=\frac{n!}{z_\la}.$$
\end{Ex}

We can also find the size of the group with this.

\begin{Ex}
We ask, how many rotation in 3D fix a cube? If we fix $x$ to be a corner of the cube, then 
$$|\Stab(x)|=3,\quad |\Orb(x)|=8,$$
then we have $24$ elements in our group.\par 
We could also fix an edge to get $2$ and $12$ or fixing faces $4$ and $6$.
\end{Ex}

\subsection{Burnside's Lemma}

\emph{It's actually not Burnside but Frobenius' lemma}. With this result we will count orbits.  The question now is \emph{in how many ways can we 2-color the faces of a cube up to rotation?} It's 10, not 8. \red{What did I overcount?}

\begin{Lem}
    The number of orbits of an action is 
    $$\frac{1}{|G|}\sum_{g\in G}|\Fix(g)|$$
    where $\Fix(g)=\set{x\in X\:\ g\.x=x}$.
\end{Lem}

To solve the previous question we have that the key is the phrase ``up to rotation''. A coloring up to rotation is an orbit under $F$ of 2-colorings of a labeled cube. There are $2^6$ such colorings. Now we have that the number of orbits is 
$$\frac{1}{24}\left(2^6+8\.2+6\.2^3+6\.2^3+3\.2^4\right)$$
identity, 120, 90 deg through face, 6 edge rotations, and the last one is through the face.
%%%%%%%%%%%% Contents end %%%%%%%%%%%%%%%%
\ifx\nextra\undefined
\printindex
\else\fi
\nocite{*}
\bibliographystyle{plain}
\bibliography{bibiCombi2.bib}
\end{document} 

